---
title: Software-Defined Assets | Dagster
description: A software-defined asset is a description of how to compute the contents of a particular data asset.
---

# Software-Defined Assets

A software-defined asset is a description of how to compute the contents of a particular data asset.

## Relevant APIs

| Name                                  | Description                                                                                                                                                                                                                                           |
| ------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <PyObject object="asset" decorator /> | A decorator used to define assets.                                                                                                                                                                                                                    |
| <PyObject object="AssetGroup" />      | A group of software-defined assets.                                                                                                                                                                                                                   |
| <PyObject object="SourceAsset" />     | A class that describes an asset, but doesn't define how to compute it. Within an <PyObject object="AssetGroup" />, <PyObject object="SourceAsset" />s are used to represent assets that other assets depend on, but can't be materialized themselves. |

## Overview

An "asset" is an object in persistent storage, e.g. a table, a file, or a persisted machine learning model. A software-defined asset is a Dagster object that couples an asset to the function and upstream assets that are used to produce its contents. Software-defined assets enable a declarative approach to data management, in which your code is the source of truth on what data assets should exist and how those assets are computed.

A software-defined asset includes three main components:

- An <PyObject object="AssetKey" />, which is a handle for referring to the asset.
- A set of upstream asset keys, which refer to assets that the contents of the software-defined asset are derived from.
- An [op](/concepts/ops-jobs-graphs/ops), which is a function responsible for computing the contents of the asset from its upstream dependencies.

A crucial distinction between software-defined assets and [ops](/concepts/ops-jobs-graphs/ops) is that software-defined assets know about their dependencies, while ops do not. Ops aren't hooked up to dependencies until they're placed inside a [graph](/concepts/ops-jobs-graphs/jobs-graphs).

"Materializing" an asset is the act of running its op and saving the results to persistent storage. You can initiate materializations from [Dagit](/concepts/dagit/dagit), Dagster's web UI, or by invoking Python APIs. By default, assets are materialized to pickle files on your local filesystem, but materialization behavior is [fully customizable](#customizing-how-assets-are-materialized-with-io-managers).

A single software-defined asset might be represented in multiple storage environments - e.g. it might have a "production" version and a "staging" version.

## Defining assets

### A basic software-defined asset

The easiest way to create a software-defined asset is with the <PyObject object="asset" decorator /> decorator.

```python file=/concepts/assets/basic_asset_definition.py
from dagster import asset


@asset
def my_asset():
    return [1, 2, 3]
```

By default, the name of the decorated function, `my_asset`, is used as the asset key. The decorated function forms the asset's op: it's responsible for producing the asset's contents. This asset doesn't depend on any other assets.

### Assets with dependencies

- [Basic dependencies](#defining-basic-dependencies)
- [Explicit dependencies](#defining-explicit-dependencies)
- [External asset dependencies](#defining-external-asset-dependencies)

#### Defining basic dependencies

Software-defined assets can depend on other software-defined assets. The easiest way to define an asset dependency is to include an upstream asset name as an argument to the decorated function.

In the following example, `downstream_asset` depends on `upstream_asset`. That means that the contents of `upstream_asset` are provided to the function that computes the contents of `downstream_asset`.

```python file=/concepts/assets/asset_dependency.py startafter=start_marker endbefore=end_marker
@asset
def upstream_asset():
    return [1, 2, 3]


@asset
def downstream_asset(upstream_asset):
    return upstream_asset + [4]
```

#### Defining explicit dependencies

If defining dependencies by matching argument names to upstream asset names feels too magical for your tastes, you can also define dependencies in a more explicit way:

```python file=/concepts/assets/explicit_string_asset_dependency.py
from dagster import AssetIn, asset


@asset
def upstream_asset():
    return [1, 2, 3]


@asset(ins={"upstream": AssetIn("upstream_asset")})
def downstream_asset(upstream):
    return upstream + [4]
```

In this case, `ins={"upstream": AssetIn("upstream_asset")}` declares that the contents of the asset with the key `upstream_asset` will be provided to the function argument named `upstream`.

Asset keys can also be provided to <PyObject object="AssetIn" /> to explicitly identify the asset. For example:

```python file=/concepts/assets/explicit_asset_dependency_asset_keys.py
from dagster import AssetIn, AssetKey, asset

# One way of providing explicit asset keys:


@asset(ins={"upstream": AssetIn(asset_key="upstream_asset")})
def downstream_asset(upstream):
    return upstream + [4]


# Another way:


@asset(ins={"upstream": AssetIn(asset_key=AssetKey("upstream_asset"))})
def another_downstream_asset(upstream):
    return upstream + [10]
```

#### Defining external asset dependencies

Software-defined assets frequently depend on assets that are generated elsewhere. Using <PyObject object="SourceAsset" />, you can include these external assets and allow the assets in your <PyObject object="AssetGroup" /> to depend on them.

For example:

```python file=/concepts/assets/source_asset.py startafter=start_marker endbefore=end_marker
from dagster import AssetGroup, AssetKey, SourceAsset, asset

my_source_asset = SourceAsset(key=AssetKey("a_source_asset"))


@asset
def my_derived_asset(a_source_asset):
    return a_source_asset + [4]


asset_group = AssetGroup(assets=[my_derived_asset], source_assets=[my_source_asset])
```

**Note**: The source asset's asset key must be provided as the argument to downstream assets. In the previous example, the asset key is `a_source_asset` and not `my_source_asset`.

You can also re-use assets across repositories by including them as source assets:

```python file=/concepts/assets/cross_repository_asset.py
from dagster import AssetGroup, AssetKey, SourceAsset, asset, repository


@asset
def repository_a_asset():
    return 5


repository_a_asset_group = AssetGroup(assets=[repository_a_asset])


@repository
def repository_a():
    return [repository_a_asset_group]


repository_a_source_asset = SourceAsset(key=AssetKey("repository_a_asset"))


@asset
def repository_b_asset(repository_a_asset):
    return repository_a_asset + 6


repository_b_asset_group = AssetGroup(
    assets=[repository_b_asset], source_assets=[repository_a_source_asset]
)


@repository
def repository_b():
    return [repository_b_asset_group]
```

Using source assets has a few advantages over having the code inside of an asset's op load the data:

- **Dagit can show asset lineage that includes the source assets**. If a different <PyObject object="AssetGroup" /> in the same [workspace](/concepts/repositories-workspaces/workspaces) contains an asset definition with the same asset key as a <PyObject object="SourceAsset" />, Dagit can represent the asset lineage across those groups.
- **Dagster can use data-loading code factored into an <PyObject object="IOManager" /> to load the contents of the source asset**.
- **Asset dependencies can be written in a consistent way,** independent of whether they're downstream from a source asset or a derived asset. This makes it easy to swap out a source asset for a derived asset and vice versa.

## Combining assets in groups

To materialize assets or load them in Dagit, you first need to combine them into an <PyObject object="AssetGroup" />, which is a set of assets with no unsatisfied dependencies. For example:

```python file=/concepts/assets/asset_group.py startafter=start_marker endbefore=end_marker
from dagster import AssetGroup, asset


@asset
def upstream_asset():
    return [1, 2, 3]


@asset
def downstream_asset(upstream_asset):
    return upstream_asset + [4]


asset_group = AssetGroup([upstream_asset, downstream_asset])
```

To save you from needing to add each asset individually to the group, Dagster provides the <PyObject object="AssetGroup" method="from_package_name" /> method for building <PyObject object="AssetGroup" />s out of all the assets within all Python modules underneath a Python package:

```python file=/concepts/assets/from_package_name.py
from dagster import AssetGroup

asset_group = AssetGroup.from_package_name(
    "docs_snippets.concepts.assets.package_with_assets"
)
```

Once assets are bundled into an asset group, you can:

- [View them in Dagit](#viewing-assets-in-dagit).
- [Materialize an ad-hoc set of them in Dagit](#materializing-assets-in-dagit).
- [Build a job](#building-jobs-that-materialize-assets), which materializes a fixed selection of the assets in the group, and can be put on a schedule or sensor.

## Viewing and materializing assets in Dagit

### Loading assets into Dagit

To view and materialize assets in Dagit, you can point it at a module that contains an <PyObject object="AssetGroup" />. E.g.

    dagit -m module_with_asset_group

If you want Dagit to contain both an asset group and a set of [jobs](/concepts/ops-jobs-graphs/jobs-graphs) that target the assets, you can place the <PyObject object="AssetGroup" /> and jobs together inside a [repository](/concepts/repositories-workspaces/repositories).

### Viewing assets in Dagit

- [All assets](#all-assets)
- [Details for an asset](#asset-details)
- [Dependency graph](#dependency-graph)
- [Upstream changes](#upstream-changed-indicator)

#### All assets

To view a list of all your assets, click **Assets** in the top-right corner of the page. This opens the Asset Catalog:

<img
alt="Asset Catalog"
src="/images/concepts/assets/software-defined-assets/catalog.png"
/>

#### Asset details

View the Asset Details page for an asset by clicking on its name:

<img
alt="Asset Details"
src="/images/concepts/assets/software-defined-assets/details.png"
/>

#### Dependency graph

To view a graph of all assets and their dependencies, you can:

- Click the graph icon to the upper-left of the Asset Catalog
- Click **View in Graph** on any asset

<img
alt="Asset Graph"
src="/images/concepts/assets/software-defined-assets/graph.png"
/>

#### Upstream changed indicator

On occasion, you might see an **upstream changed** indicator on an asset in the dependency graph or on the Asset Details page:

<img
alt="Asset Graph with an upstream changed indicator"
src="/images/concepts/assets/software-defined-assets/upstream-changed.png"
/>

This occurs when a downstream asset's last materialization took place **earlier than the asset it depends on.** Dagit displays this alert to notify you that the contents of an asset may be stale. For example:

- `comments` is upstream of `comment_stories`
- `comment_stories` depends on `comments`
- `comment_stories` was last materialized on February 25 at **5:30PM**
- `comments` was last materialized on February 25 at **7:05PM**

In this case, the contents of `comment_stories` may be outdated, as the most recent data from `comments` wasn't used to compute them.

You can resolve this issue by re-materializing the downstream asset. This will re-compute the contents with the most recent data/changes to its upstream dependency.

<Note>
  Currently, the <strong>upstream changed</strong> indicator won't display in
  the following scenarios:
  <ul>
    <li>The upstream asset is in another asset group or job</li>
    <li>The assets are partitioned</li>
  </ul>
</Note>

### Materializing assets in Dagit

There are a couple ways in Dagit to launch a run that materializes assets:

- Navigate to the Asset Details Page for the asset and click the "Materialize" button in the upper right corner.
- In the graph view of the Asset Catalog page, click the "Materialize" button in the upper right corner. You can click on assets to collect a subset to materialize.

## Customizing how assets are materialized with IO managers

By default, materializing an asset will pickle it to a local file named "my_asset", in a temporary directory. You can specify this directory by providing a value for the `local_artifact_storage` property in your dagster.yaml file.

[IO managers](/concepts/io-management/io-managers) enable fully overriding this behavior and storing asset contents in any way you wish - e.g. writing them as tables in a database or as objects in a cloud object store. Dagster also provides built-in IO managers that pickle assets to AWS S3 (<PyObject module="dagster_aws.s3" object="s3_pickle_io_manager" />), Azure Blob Storage (<PyObject module="dagster_azure.adls2" object="adls2_pickle_io_manager" />), and GCS (<PyObject module="dagster_gcp.gcs" object="gcs_pickle_io_manager" />), or you can write your own.

To apply an IO manager to a set of assets, you can include it with them in an <PyObject object="AssetGroup" />.

```python file=/concepts/assets/asset_io_manager.py startafter=start_marker endbefore=end_marker
from dagster_aws.s3 import s3_pickle_io_manager, s3_resource

from dagster import AssetGroup, asset


@asset
def upstream_asset():
    return [1, 2, 3]


@asset
def downstream_asset(upstream_asset):
    return upstream_asset + [4]


asset_group = AssetGroup(
    [upstream_asset, downstream_asset],
    resource_defs={"io_manager": s3_pickle_io_manager, "s3": s3_resource},
)
```

This example also includes `"s3": s3_resource`, because the `s3_pickle_io_manager` depends on an s3 resource.

When `upstream_asset` is materialized, the value `[1, 2, 3]` will be will be pickled and stored in an object on S3. When `downstream_asset` is materialized, the value of `upstream_asset` will be read from S3 and depickled, and `[1, 2, 3, 4]` will be pickled and stored in a different object on S3.

Different assets can have different IO managers:

```python file=/concepts/assets/asset_different_io_managers.py startafter=start_marker endbefore=end_marker
from dagster_aws.s3 import s3_pickle_io_manager, s3_resource

from dagster import AssetGroup, asset, fs_io_manager


@asset(io_manager_key="s3_io_manager")
def upstream_asset():
    return [1, 2, 3]


@asset(io_manager_key="fs_io_manager")
def downstream_asset(upstream_asset):
    return upstream_asset + [4]


asset_group = AssetGroup(
    [upstream_asset, downstream_asset],
    resource_defs={
        "s3_io_manager": s3_pickle_io_manager,
        "s3": s3_resource,
        "fs_io_manager": fs_io_manager,
    },
)
```

When `upstream_asset` is materialized, the value `[1, 2, 3]` will be will be pickled and stored in an object on S3. When `downstream_asset` is materialized, the value of `upstream_asset` will be read from S3 and depickled, and `[1, 2, 3, 4]` will be pickled and stored in a file on the local filesystem.

The same assets can be bound to different resources and IO managers in different environments. For example, for local development, you might want to store assets on your local filesystem while, in production, you might want to store the assets in S3.

```python file=/concepts/assets/asset_io_manager_prod_local.py startafter=start_marker endbefore=end_marker
from dagster_aws.s3 import s3_pickle_io_manager, s3_resource

from dagster import AssetGroup, asset, fs_io_manager


@asset
def upstream_asset():
    return [1, 2, 3]


@asset
def downstream_asset(upstream_asset):
    return upstream_asset + [4]


prod_asset_group = AssetGroup(
    [upstream_asset, downstream_asset],
    resource_defs={"io_manager": s3_pickle_io_manager, "s3": s3_resource},
)

local_asset_group = AssetGroup(
    [upstream_asset, downstream_asset],
    resource_defs={"io_manager": fs_io_manager},
)
```

## Building jobs that materialize assets

You can define a job that materializes a fixed selection of the assets in an <PyObject object="AssetGroup" /> each time it runs.

The following snippet shows examples of three different jobs you might create out of an <PyObject object="AssetGroup" />.

```python file=/concepts/assets/build_job.py startafter=start_marker endbefore=end_marker
from dagster import AssetGroup, asset


@asset
def upstream():
    return [1, 2, 3]


@asset
def downstream_1(upstream):
    return upstream + [4]


@asset
def downstream_2(upstream):
    return len(upstream)


asset_group = AssetGroup([upstream, downstream_1, downstream_2])

all_assets = asset_group.build_job(name="my_asset_job")

downstream_assets = asset_group.build_job(
    name="my_asset_job", selection=["upstream", "downstream_1"]
)

upstream_and_downstream_1 = asset_group.build_job(
    name="my_asset_job", selection="*downstream_1"
)
```

Multiple jobs within the same repository can target overlapping sets of assets.

Like regular jobs, asset jobs can be placed on [schedules](/concepts/partitions-schedules-sensors/schedules) and [sensors](/concepts/partitions-schedules-sensors/sensors).

## Testing

When writing unit tests, you can treat the function decorated by `@asset` as a regular python function.

Consider a simple asset with no upstream dependencies:

```python file=/concepts/assets/asset_testing.py startafter=start_simple_asset endbefore=end_simple_asset
@asset
def my_simple_asset():
    return [1, 2, 3]
```

When writing a unit test, you can directly invoke the decorated function.

```python file=/concepts/assets/asset_testing.py startafter=start_test_simple_asset endbefore=end_test_simple_asset
def test_my_simple_asset():
    result = my_simple_asset()
    assert result == [1, 2, 3]
```

If you have an asset with upstream dependencies:

```python file=/concepts/assets/asset_testing.py startafter=start_more_complex_asset endbefore=end_more_complex_asset
@asset
def more_complex_asset(my_simple_asset):
    return my_simple_asset + [4, 5, 6]
```

You can manually provide values for those dependencies in your unit test. This allows you to test assets in isolation from one another.

```python file=/concepts/assets/asset_testing.py startafter=start_test_more_complex_asset endbefore=end_test_more_complex_asset
def test_more_complex_asset():
    result = more_complex_asset([0])
    assert result == [0, 4, 5, 6]
```

If you use a context object in your function, `@asset` will provide the correct context during execution. When writing a unit test, you can mock it with <PyObject object="build_op_context" />. You can use <PyObject object="build_op_context" /> to generate the `context` object because under the hood the function decorated by `@asset` is an op.

Consider this asset that uses a resource:

```python file=/concepts/assets/asset_testing.py startafter=start_with_context_asset endbefore=end_with_context_asset
@asset
def uses_context(context):
    return context.resources.foo
```

When writing a unit test, use <PyObject object="build_op_context" /> to mock the `context` and provide values for testing.

```python file=/concepts/assets/asset_testing.py startafter=start_test_with_context_asset endbefore=end_test_with_context_asset
def test_uses_context():
    context = build_op_context(resources={"foo": "bar"})
    result = uses_context(context)
    assert result == "bar"
```

## Examples

### Multi-component asset keys

Assets are often objects in systems with hierarchical namespaces, like filesystems. Because of this, it often makes sense for an asset key to be a list of strings, instead of just a single string.

```python file=/concepts/assets/multi_component_asset_key.py startafter=start_marker endbefore=end_marker
from dagster import AssetIn, asset


@asset(namespace=["one", "two", "three"])
def upstream_asset():
    return [1, 2, 3]


@asset(ins={"upstream_asset": AssetIn(namespace=["one", "two", "three"])})
def downstream_asset(upstream_asset):
    return upstream_asset + [4]
```

### Explicit dependencies

If defining dependencies by matching argument names to upstream asset names feels too magical for your tastes, you can also define dependencies in a more explicit way:

```python file=/concepts/assets/explicit_asset_dependency.py
ENOENT: no such file or directory, open '/Users/erincochran/Desktop/dagster-repo/examples/docs_snippets/docs_snippets/concepts/assets/explicit_asset_dependency.py'
```

In this case, `ins={"upstream": AssetIn("upstream_asset")}` declares that the contents of the asset with the key `upstream_asset` will be provided to the function argument named `upstream`.

### Attaching metadata

Dagster supports attaching arbitrary [metadata](/\_apidocs/ops#dagster.MetadataEntry) to assets. To attach metadata, supply a `metadata` dictionary to the asset:

```python file=/concepts/assets/asset_metadata.py startafter=start_example endbefore=end_example
@asset(metadata={"cereal_name": "Sugar Sprinkles"})
def cereal_asset():
    return 5
```

Asset metadata can be viewed in Dagit on the [Asset Detail page](/concepts/dagit/dagit#asset-details).

## Further Reading

Interested in learning more about software-defined assets and working through a more complex example? Check out our [guide on software-defined assets](/guides/dagster/software-defined-assets) and our [example project](https://github.com/dagster-io/dagster/tree/master/examples/modern_data_stack_assets) that integrates software-defined assets with other Modern Data Stack tools.

## See it in action

For more examples of software-defined assets, check out the following in our [SDA Hacker News example](https://github.com/dagster-io/dagster/tree/master/examples/hacker_news_assets):

- [Defining an asset](https://github.com/dagster-io/dagster/blob/master/examples/hacker_news_assets/hacker_news_assets/activity_analytics/assets/activity_forecast.py)
- [Loading assets from dbt](https://github.com/dagster-io/dagster/blob/master/examples/hacker_news_assets/hacker_news_assets/activity_analytics/\__init\_\_.py)
- [Per-asset IO manager](https://github.com/dagster-io/dagster/blob/master/examples/hacker_news_assets/hacker_news_assets/core/assets/items.py)
- [Partitioned assets](https://github.com/dagster-io/dagster/blob/master/examples/hacker_news_assets/hacker_news_assets/core/assets/items.py)
- [AssetGroups](https://github.com/dagster-io/dagster/blob/master/examples/hacker_news_assets/hacker_news_assets/core/\__init\_\_.py)

Our [Modern Data Stack example](https://github.com/dagster-io/dagster/tree/master/examples/modern_data_stack_assets) also covers:

- [Defining assets](https://github.com/dagster-io/dagster/blob/master/examples/modern_data_stack_assets/modern_data_stack_assets/assets.py)
- [Loading assets from dbt](https://github.com/dagster-io/dagster/blob/master/examples/modern_data_stack_assets/modern_data_stack_assets/assets.py)
- [Loading assets from Airbyte](https://github.com/dagster-io/dagster/blob/master/examples/modern_data_stack_assets/modern_data_stack_assets/assets.py)

Our [Bollinger example](https://github.com/dagster-io/dagster/tree/master/examples/bollinger) also covers software-defined assets
