---
title: 'snowflake polars (dagster-snowflake-polars)'
title_meta: 'snowflake polars (dagster-snowflake-polars) API Documentation - Build Better Data Pipelines | Python Reference Documentation for Dagster'
description: 'snowflake polars (dagster-snowflake-polars) Dagster API | Comprehensive Python API documentation for Dagster, the data orchestration platform. Learn how to build, test, and maintain data pipelines with our detailed guides and examples.'
last_update:
  date: '2025-12-05'
custom_edit_url: null
---

<div class="section" id="snowflake-polars-dagster-snowflake-polars">

# Snowflake Polars (dagster-snowflake-polars)

This library provides an integration with Snowflake and Polars, allowing you to use Polars DataFrames with Snowflake storage.

<div class="section" id="i-o-manager">

## I/O Manager

<dl>
    <dt><Link class="anchor" id='dagster_snowflake_polars.snowflake_polars_io_manager'>dagster_snowflake_polars.snowflake_polars_io_manager <a href='https://github.com/dagster-io/dagster/blob/master/python_modules/libraries/dagster-snowflake-polars/dagster_snowflake_polars/snowflake_polars_type_handler.py#L240' className='source-link' target='_blank' rel='noopener noreferrer'>[source]</a><a href="#dagster_snowflake_polars.snowflake_polars_io_manager" class="hash-link"></a></Link></dt>
    <dd>

        :::info[beta]
        This API is currently in beta, and may have breaking changes in minor version releases, with behavior changes in patch releases.


        :::

    An I/O manager definition that reads inputs from and writes Polars DataFrames to Snowflake. When
    using the snowflake_polars_io_manager, any inputs and outputs without type annotations will be loaded
    as Polars DataFrames.

    Returns: IOManagerDefinition


    Examples:

        ```python
        from dagster_snowflake_polars import snowflake_polars_io_manager
        from dagster import asset, Definitions
        import polars as pl

        @asset(
            key_prefix=["my_schema"],  # will be used as the schema in snowflake
        )
        def my_table() -> pl.DataFrame:  # the name of the asset will be the table name
            ...

        defs = Definitions(
            assets=[my_table],
            resources={
                "io_manager": snowflake_polars_io_manager.configured({
                    "database": "my_database",
                    "account": {"env": "SNOWFLAKE_ACCOUNT"}
                })
            }
        )
        ```
    You can set a default schema to store the assets using the `schema` configuration value of the Snowflake I/O
    Manager. This schema will be used if no other schema is specified directly on an asset or op.

        ```python
        defs = Definitions(
            assets=[my_table],
            resources={"io_manager": snowflake_polars_io_manager.configured(
                {"database": "my_database", "schema": "my_schema"} # will be used as the schema
            )}
        )
        ```
    On individual assets, you can also specify the schema where they should be stored using metadata or
    by adding a `key_prefix` to the asset key. If both `key_prefix` and metadata are defined, the metadata will
    take precedence.

        ```python
        @asset(
            key_prefix=["my_schema"],  # will be used as the schema in snowflake
        )
        def my_table() -> pl.DataFrame:
            ...

        @asset(
            metadata={"schema": "my_schema"}  # will be used as the schema in snowflake
        )
        def my_other_table() -> pl.DataFrame:
            ...
        ```
    For ops, the schema can be specified by including a “schema” entry in output metadata.

        ```python
        @op(
            out={"my_table": Out(metadata={"schema": "my_schema"})}
        )
        def make_my_table() -> pl.DataFrame:
            ...
        ```
    If none of these is provided, the schema will default to “public”.

    To only use specific columns of a table as input to a downstream op or asset, add the metadata “columns” to the
    In or AssetIn.

        ```python
        @asset(
            ins={"my_table": AssetIn("my_table", metadata={"columns": ["a"]})}
        )
        def my_table_a(my_table: pl.DataFrame) -> pl.DataFrame:
            # my_table will just contain the data from column "a"
            ...
        ```

    </dd>

</dl>
<dl>
    <dt><Link class="anchor" id='dagster_snowflake_polars.SnowflakePolarsIOManager'>`class` dagster_snowflake_polars.SnowflakePolarsIOManager <a href='https://github.com/dagster-io/dagster/blob/master/python_modules/libraries/dagster-snowflake-polars/dagster_snowflake_polars/snowflake_polars_type_handler.py#L138' className='source-link' target='_blank' rel='noopener noreferrer'>[source]</a><a href="#dagster_snowflake_polars.SnowflakePolarsIOManager" class="hash-link"></a></Link></dt>
    <dd>

        :::info[beta]
        This API is currently in beta, and may have breaking changes in minor version releases, with behavior changes in patch releases.


        :::

    An I/O manager definition that reads inputs from and writes Polars DataFrames to Snowflake. When
    using the SnowflakePolarsIOManager, any inputs and outputs without type annotations will be loaded
    as Polars DataFrames.

    Returns: IOManagerDefinition


    Examples:

        ```python
        from dagster_snowflake_polars import SnowflakePolarsIOManager
        from dagster import asset, Definitions, EnvVar
        import polars as pl

        @asset(
            key_prefix=["my_schema"],  # will be used as the schema in snowflake
        )
        def my_table() -> pl.DataFrame:  # the name of the asset will be the table name
            ...

        defs = Definitions(
            assets=[my_table],
            resources={
                "io_manager": SnowflakePolarsIOManager(database="MY_DATABASE", account=EnvVar("SNOWFLAKE_ACCOUNT"))
            }
        )
        ```
    You can set a default schema to store the assets using the `schema` configuration value of the Snowflake I/O
    Manager. This schema will be used if no other schema is specified directly on an asset or op.

        ```python
        defs = Definitions(
            assets=[my_table],
            resources={
                "io_manager": SnowflakePolarsIOManager(database="my_database", schema="my_schema")
            }
        )
        ```
    On individual assets, you can also specify the schema where they should be stored using metadata or
    by adding a `key_prefix` to the asset key. If both `key_prefix` and metadata are defined, the metadata will
    take precedence.

        ```python
        @asset(
            key_prefix=["my_schema"],  # will be used as the schema in snowflake
        )
        def my_table() -> pl.DataFrame:
            ...

        @asset(
            metadata={"schema": "my_schema"}  # will be used as the schema in snowflake
        )
        def my_other_table() -> pl.DataFrame:
            ...
        ```
    For ops, the schema can be specified by including a “schema” entry in output metadata.

        ```python
        @op(
            out={"my_table": Out(metadata={"schema": "my_schema"})}
        )
        def make_my_table() -> pl.DataFrame:
            ...
        ```
    If none of these is provided, the schema will default to “public”.

    To only use specific columns of a table as input to a downstream op or asset, add the metadata “columns” to the
    In or AssetIn.

        ```python
        @asset(
            ins={"my_table": AssetIn("my_table", metadata={"columns": ["a"]})}
        )
        def my_table_a(my_table: pl.DataFrame) -> pl.DataFrame:
            # my_table will just contain the data from column "a"
            ...
        ```

    </dd>

</dl>
</div>

<div class="section" id="type-handler">

## Type Handler

<dl>
    <dt><Link class="anchor" id='dagster_snowflake_polars.SnowflakePolarsTypeHandler'>`class` dagster_snowflake_polars.SnowflakePolarsTypeHandler <a href='https://github.com/dagster-io/dagster/blob/master/python_modules/libraries/dagster-snowflake-polars/dagster_snowflake_polars/snowflake_polars_type_handler.py#L23' className='source-link' target='_blank' rel='noopener noreferrer'>[source]</a><a href="#dagster_snowflake_polars.SnowflakePolarsTypeHandler" class="hash-link"></a></Link></dt>
    <dd>

        :::info[beta]
        This API is currently in beta, and may have breaking changes in minor version releases, with behavior changes in patch releases.


        :::

    Plugin for the Snowflake I/O Manager that can store and load Polars DataFrames as Snowflake tables.

    This handler uses Polars’ native write_database method with ADBC (Arrow Database Connectivity)
    for efficient data transfer without converting to pandas.



    Examples:

        ```python
        from dagster_snowflake import SnowflakeIOManager
        from dagster_snowflake_polars import SnowflakePolarsTypeHandler
        from dagster import Definitions, EnvVar

        class MySnowflakeIOManager(SnowflakeIOManager):
            @staticmethod
            def type_handlers() -> Sequence[DbTypeHandler]:
                return [SnowflakePolarsTypeHandler()]

        @asset(
            key_prefix=["my_schema"],  # will be used as the schema in snowflake
        )
        def my_table() -> pl.DataFrame:  # the name of the asset will be the table name
            ...

        defs = Definitions(
            assets=[my_table],
            resources={
                "io_manager": MySnowflakeIOManager(database="MY_DATABASE", account=EnvVar("SNOWFLAKE_ACCOUNT"), ...)
            }
        )
        ```

    </dd>

</dl>
</div></div>
