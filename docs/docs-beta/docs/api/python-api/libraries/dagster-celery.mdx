---
title: 'celery (dagster-celery)'
title_meta: 'celery (dagster-celery) API Documentation - Build Better Data Pipelines | Python Reference Documentation for Dagster'
description: 'celery (dagster-celery) Dagster API | Comprehensive Python API documentation for Dagster, the data orchestration platform. Learn how to build, test, and maintain data pipelines with our detailed guides and examples.'
last_update:
  date: '2025-01-23'
---

<div class="section" id="celery-dagster-celery">


# Celery (dagster-celery)

<div class="section" id="quickstart">


## Quickstart

To get a local rabbitmq broker started and available via the default
`pyamqp://guest@localhost:5672`, in the `dagster/python_modules/libraries/dagster-celery/`
directory run:

    ```bash
    docker-compose up
    ```
To run a celery worker:

    ```bash
    celery -A dagster_celery.app worker -l info
    ```
To start multiple workers in the background, run:

    ```bash
    celery multi start w2 -A dagster_celery.app -l info
    ```
To execute a job using the celery-backed executor, you’ll need to set the job’s `executor_def` to
the celery_executor.

    ```python
    from dagster import job
    from dagster_celery import celery_executor

    @job(executor_def=celery_executor)
    def my_job():
        pass
    ```
<div class="section" id="monitoring-your-celery-tasks">


### Monitoring your Celery tasks

We advise using [Flower](https://celery.readthedocs.io/en/latest/userguide/monitoring.html#flower-real-time-celery-web-monitor):

    ```bash
    celery -A dagster_celery.app flower
    ```
</div>


<div class="section" id="customizing-the-celery-broker-backend-and-other-app-configuration">


### Customizing the Celery broker, backend, and other app configuration

By default this will use `amqp://guest:**@localhost:5672//` as the Celery broker URL and
`rpc://` as the results backend. In production, you will want to change these values. Pending the
introduction of a dagster_celery CLI, that would entail writing a Python module `my_module` as
follows:

    ```python
    from celery import Celery

    from dagster_celery.tasks import create_task

    app = Celery('dagster', broker_url='some://custom@value', ...)

    execute_plan = create_task(app)

    if __name__ == '__main__':
        app.worker_main()
    ```
You can then run the celery worker using:

    ```bash
    celery -A my_module worker --loglevel=info
    ```
This customization mechanism is used to implement <cite>dagster_celery_k8s</cite> and <cite>dagster_celery_k8s</cite> which delegate the execution of steps to ephemeral kubernetes pods and docker containers, respectively.

</div></div>


<div class="section" id="api">


## API

<dl>
    <dt><Link id='dagster_celery.celery_executor'>dagster_celery.celery_executor ExecutorDefinition</Link></dt>
    <dd>

        <div className='lineblock'> </div>

    Celery-based executor.

    The Celery executor exposes config settings for the underlying Celery app under
    the `config_source` key. This config corresponds to the “new lowercase settings” introduced
    in Celery version 4.0 and the object constructed from config will be passed to the
    `celery.Celery` constructor as its `config_source` argument.
    (See [https://docs.celeryq.dev/en/stable/userguide/configuration.html](https://docs.celeryq.dev/en/stable/userguide/configuration.html) for details.)

    The executor also exposes the `broker`, <cite>backend</cite>, and `include` arguments to the
    `celery.Celery` constructor.

    In the most common case, you may want to modify the `broker` and `backend` (e.g., to use
    Redis instead of RabbitMQ). We expect that `config_source` will be less frequently
    modified, but that when solid executions are especially fast or slow, or when there are
    different requirements around idempotence or retry, it may make sense to execute jobs
    with variations on these settings.

    To use the <cite>celery_executor</cite>, set it as the <cite>executor_def</cite> when defining a job:

        ```python
        from dagster import job
        from dagster_celery import celery_executor

        @job(executor_def=celery_executor)
        def celery_enabled_job():
            pass
        ```
    Then you can configure the executor as follows:

        ```YAML
        execution:
          config:
            broker: 'pyamqp://guest@localhost//'  # Optional[str]: The URL of the Celery broker
            backend: 'rpc://' # Optional[str]: The URL of the Celery results backend
            include: ['my_module'] # Optional[List[str]]: Modules every worker should import
            config_source: # Dict[str, Any]: Any additional parameters to pass to the
                #...       # Celery workers. This dict will be passed as the `config_source`
                #...       # argument of celery.Celery().
        ```
    Note that the YAML you provide here must align with the configuration with which the Celery
    workers on which you hope to run were started. If, for example, you point the executor at a
    different broker than the one your workers are listening to, the workers will never be able to
    pick up tasks for execution.


    </dd>

</dl>
</div>


<div class="section" id="cli">


## CLI

The `dagster-celery` CLI lets you start, monitor, and terminate workers.

<div class="section" id="dagster-celery-worker-start">


### dagster-celery worker start

Start a dagster celery worker.

    ```shell
    dagster-celery worker start [OPTIONS] [ADDITIONAL_ARGS]...
    ```
Options:

<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-n'>-n, --name \<name></Link></dt>
    <dd>
    The name of the worker. Defaults to a unique name prefixed with “dagster-” and ending with the hostname.
    </dd>

</dl>
<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-y'>-y, --config-yaml \<config_yaml></Link></dt>
    <dd>
    Specify the path to a config YAML file with options for the worker. This is the same config block that you provide to dagster_celery.celery_executor when configuring a job for execution with Celery, with, e.g., the URL of the broker to use.
    </dd>

</dl>
<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-q'>-q, --queue \<queue></Link></dt>
    <dd>
    Names of the queues on which this worker should listen for tasks.  Provide multiple -q arguments to specify multiple queues. Note that each celery worker may listen on no more than four queues.
    </dd>

</dl>
<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-d'>-d, --background</Link></dt>
    <dd>
    Set this flag to run the worker in the background.
    </dd>

</dl>
<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-i'>-i, --includes \<includes></Link></dt>
    <dd>
    Python modules the worker should import. Provide multiple -i arguments to specify multiple modules.
    </dd>

</dl>
<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-l'>-l, --loglevel \<loglevel></Link></dt>
    <dd>
    Log level for the worker.
    </dd>

</dl>
<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-A'>-A, --app \<app></Link></dt>
    <dd>

    </dd>

</dl>
Arguments:

<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-start-arg-ADDITIONAL_ARGS'>ADDITIONAL_ARGS</Link></dt>
    <dd>
    Optional argument(s)
    </dd>

</dl>
</div>


<div class="section" id="dagster-celery-worker-list">


### dagster-celery worker list

List running dagster-celery workers. Note that we use the broker to contact the workers.

    ```shell
    dagster-celery worker list [OPTIONS]
    ```
Options:

<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-list-y'>-y, --config-yaml \<config_yaml></Link></dt>
    <dd>
    Specify the path to a config YAML file with options for the workers you are trying to manage. This is the same config block that you provide to dagster_celery.celery_executor when configuring a job for execution with Celery, with, e.g., the URL of the broker to use. Without this config file, you will not be able to find your workers (since the CLI won’t know how to reach the broker).
    </dd>

</dl>
</div>


<div class="section" id="dagster-celery-worker-terminate">

### dagster-celery worker terminate

Shut down dagster-celery workers. Note that we use the broker to send signals to the workers to terminate – if the broker is not running, this command is a no-op. Provide the argument NAME to terminate a specific worker by name.

    ```shell
    dagster-celery worker terminate [OPTIONS] [NAME]
    ```
Options:

<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-terminate-a'>-a, --all</Link></dt>
    <dd>
    Set this flag to terminate all running workers.
    </dd>

</dl>
<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-terminate-y'>-y, --config-yaml \<config_yaml></Link></dt>
    <dd>
    Specify the path to a config YAML file with options for the workers you are trying to manage. This is the same config block that you provide to dagster_celery.celery_executor when configuring a job for execution with Celery, with, e.g., the URL of the broker to use. Without this config file, you will not be able to terminate your workers (since the CLI won’t know how to reach the broker).
    </dd>

</dl>
Arguments:

<dl>
    <dt><Link id='cmdoption-dagster-celery-worker-terminate-arg-NAME'>NAME</Link></dt>
    <dd>
    Optional argument
    </dd>

</dl>
</div></div></div>
