{
  "frontmatter": {
    "id": "azure-adls2",
    "status": "published",
    "name": "",
    "title": "Dagster &  Azure Data Lake Storage Gen 2",
    "excerpt": "Get utilities for ADLS2 and Blob Storage.",
    "partnerlink": "https://azure.microsoft.com/",
    "categories": ["Storage"],
    "enabledBy": [],
    "enables": [],
    "tags": ["dagster-supported", "storage"]
  },
  "logoFilename": "azure.svg",
  "content": "Dagster helps you use Azure Storage Accounts as part of your data pipeline. Azure Data Lake Storage Gen 2 (ADLS2) is our primary focus but we also provide utilities for Azure Blob Storage.\n\n### Installation\n\n```bash\npip install dagster-azure\n```\n\n### Example\n\n\n```python\nimport pandas as pd\nfrom dagster_azure.adls2 import ADLS2Resource, ADLS2SASToken\n\nimport dagster as dg\n\n\n@dg.asset\ndef example_adls2_asset(adls2: ADLS2Resource):\n    df = pd.DataFrame({\"column1\": [1, 2, 3], \"column2\": [\"A\", \"B\", \"C\"]})\n\n    csv_data = df.to_csv(index=False)\n\n    file_client = adls2.adls2_client.get_file_client(\n        \"my-file-system\", \"path/to/my_dataframe.csv\"\n    )\n    file_client.upload_data(csv_data, overwrite=True)\n\n\ndefs = dg.Definitions(\n    assets=[example_adls2_asset],\n    resources={\n        \"adls2\": ADLS2Resource(\n            storage_account=\"my_storage_account\",\n            credential=ADLS2SASToken(token=\"my_sas_token\"),\n        )\n    },\n)\n```\n        \n\nIn this updated code, we use `ADLS2Resource` directly instead of `adls2_resource`. The configuration is passed to `ADLS2Resource` during its instantiation.\n\n### About Azure Data Lake Storage Gen 2 (ADLS2)\n\n**Azure Data Lake Storage Gen 2 (ADLS2)** is a set of capabilities dedicated to big data analytics, built on Azure Blob Storage. ADLS2 combines the scalability, cost-effectiveness, security, and rich capabilities of Azure Blob Storage with a high-performance file system that's built for analytics and is compatible with the Hadoop Distributed File System (HDFS). This makes it an ideal choice for data lakes and big data analytics."
}
