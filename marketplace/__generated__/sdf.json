{
  "frontmatter": {
    "id": "sdf",
    "status": "published",
    "name": "SDF",
    "title": "Dagster & SDF",
    "excerpt": "Put your SDF transformations to work, directly from within Dagster.",
    "partnerlink": "https://www.sdf.com/",
    "categories": [
      "ETL"
    ],
    "enabledBy": [],
    "enables": [],
    "tags": [
      "community-supported",
      "etl"
    ]
  },
  "logoFilename": "sdf.jpeg",
  "content": "SDF can integrate seamlessly with your existing Dagster projects, providing the best-in-class transformation layer while enabling you to schedule, orchestrate, and monitor your dags in Dagster.\n\nWhen it comes time to materialize your Dagster assets, you can be confident that SDF has successfully compiled your workspace, making it safe to execute locally or against your cloud data warehouse.\n\n### Installation\n\n```bash\npip install dagster-sdf\n```\n\n### Example\n\n\n```python\nfrom pathlib import Path\n\nfrom dagster_sdf import SdfCliResource, SdfWorkspace, sdf_assets\n\nimport dagster as dg\n\nworkspace_dir = Path(__file__).joinpath(\"..\", \"./my_sdf_workspace\").resolve()\ntarget_dir = workspace_dir.joinpath(\n    \"sdf_dagster_out\"\n)  # The destination for outputs generated by SDF during execution\nenvironment = \"dbg\"  # Replace with your environment, e.g. \"prod\"\n\nworkspace = SdfWorkspace(\n    workspace_dir=workspace_dir,\n    target_dir=target_dir,\n    environment=environment,\n)\n\n\n@sdf_assets(workspace=workspace)\ndef my_sdf_assets(context: dg.AssetExecutionContext, sdf: SdfCliResource):\n    yield from sdf.cli(\n        [\"run\", \"--save\", \"info-schema\"],\n        target_dir=target_dir,\n        environment=environment,\n        context=context,\n    ).stream()\n\n\ndefs = dg.Definitions(\n    assets=[my_sdf_assets],\n    resources={\n        \"sdf\": SdfCliResource(workspace_dir=workspace_dir),\n    },\n)\n```\n        \n\n### About SDF\n\n[SDF](https://www.sdf.com/) is a multi-dialect SQL compiler, transformation framework, and analytical database engine. It natively compiles SQL dialects, like Snowflake, and connects to their corresponding data warehouses to materialize models."
}