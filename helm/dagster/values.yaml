# yamllint disable rule:line-length
# README:
# - If using a fixed tag for images, changing the image pull policy to anything other than "Always"
#   will use a cached/stale image.
# - We recommend using unique tags for user code images, as this will guarantee that the docker
#   image will be consistent for the pipeline's entire execution.
---
global:
  postgresqlSecretName: "dagster-postgresql-secret"
  # The DAGSTER_HOME env var is set by default on all nodes from this value
  dagsterHome: "/opt/dagster/dagster_home"

  # A service account name to use for this chart and all subcharts. If this is set, then
  # dagster subcharts will not create their own service accounts.
  serviceAccountName: ""

  # The name for the secret used to pass Celery broker and backend connection urls. This can
  # generally be left as the default, but can be useful if setting generateCeleryConfigSecret
  # to false below.
  celeryConfigSecretName: "dagster-celery-config-secret"

nameOverride: ""
fullnameOverride: ""
rbacEnabled: true
# Specify secrets to run containers based on images in private registries. See:
# https://kubernetes.io/docs/concepts/containers/images/#referring-to-an-imagepullsecrets-on-a-pod
imagePullSecrets: []

####################################################################################################
# Dagit: Configuration for the Dagit webserver
####################################################################################################
dagit:
  replicaCount: 1
  image:
    # When a tag is not supplied for a Dagster provided image,
    # it will default as the Helm chart version.
    repository: "docker.io/dagster/dagster-celery-k8s"
    tag: ~
    pullPolicy: Always

  # Support overriding the name prefix of the Dagit pods
  nameOverride: "dagit"

  service:
    type: ClusterIP
    # Defines the port where Dagit will serve requests; if changed, don't forget to update the
    # livenessProbe and startupProbe entries below as well.
    port: 80
    annotations: {}

  # Defines a workspace for Dagit. This should only be set if user deployments are enabled, but
  # the subchart is disabled to manage user deployments in a separate Helm release.
  # In this case, Dagit will need the addresses of the servers in order to load the user code,
  # or the name of an existing configmap to mount as the workspace file.
  workspace:
    enabled: false

    # List of servers to include in the workflow file. When set,
    # `externalConfigmap` must be empty.
    servers:
      - host: "k8s-example-user-code-1"
        port: 3030
        name: "user-code-example"

    # Defines the name of a configmap provisioned outside of the
    # Helm release to use as workspace file. When set, `servers`
    # must be empty.
    externalConfigmap: ~

  # Deploy a separate instance of Dagit in --read-only mode (can't launch runs, disable schedules, etc.)
  enableReadOnly: false

  # The timeout in milliseconds to set on database statements sent to the Dagster instance.
  dbStatementTimeout: ~

  # The log level of the uvicorn web server, defaults to warning if not set
  logLevel: ~

  # Additional environment variables to set.
  # A Kubernetes ConfigMap will be created with these environment variables. See:
  # https://kubernetes.io/docs/concepts/configuration/configmap/
  #
  # Example:
  #
  # env:
  #   ENV_ONE: one
  #   ENV_TWO: two
  env: {}

  # Additional environment variables can be retrieved and set from ConfigMaps. See:
  # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  #
  # Example:
  #
  # envConfigMaps:
  #   - name: config-map
  envConfigMaps: []

  # Additional environment variables can be retrieved and set from Secrets. See:
  # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
  #
  # Example:
  #
  # envSecrets:
  #   - name: secret
  envSecrets: []

  # Additional labels that should be included on the deployment. See:
  # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
  #
  # Example:
  # labels:
  #   my-label-key: my_label-value
  deploymentLabels: {}

  # Additional labels that should be included on the pod. See:
  # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
  #
  # Example:
  # labels:
  #   my-label-key: my_label-value
  labels: {}

  # Support Node, affinity and tolerations for Dagit pod assignment. See:
  # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  annotations: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  podSecurityContext: {}
  securityContext: {}
  resources: {}
  # If you want to specify resources, uncomment the following lines, adjust them as necessary,
  # and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
  # Readiness probe detects when the pod is ready to serve requests.
  # https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes
  readinessProbe:
    httpGet:
      path: "/dagit_info"
      port: 80
    periodSeconds: 20
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3

  # As of 0.14.0, liveness probes are disabled by default. If you want to enable them, it's recommended to also
  # enable startup probes.
  livenessProbe: {}
  startupProbe:
    enabled: false

####################################################################################################
# Compute Log Manager: Configuration for the compute log manager
####################################################################################################
computeLogManager:
  # Type can be one of [
  #   NoOpComputeLogManager,
  #   AzureBlobComputeLogManager,
  #   GCSComputeLogManager,
  #   S3ComputeLogManager,
  #   CustomComputeLogManager,
  # ]
  type: NoOpComputeLogManager
  config: {}
  ##  Uncomment this configuration if the AzureBlobComputeLogManager is selected
  #   azureBlobComputeLogManager:
  #     storageAccount: ~
  #     container: ~
  #     secretKey: ~
  #     localDir: ~
  #     prefix: ~
  ##  Uncomment this configuration if the GCSComputeLogManager is selected
  #   gcsComputeLogManager:
  #     bucket: ~
  #     localDir: ~
  #     prefix: ~
  #     jsonCredentialsEnvvar: ~
  ##  Uncomment this configuration if the S3ComputeLogManager is selected
  #   s3ComputeLogManager:
  #     bucket: ~
  #     localDir: ~
  #     prefix: ~
  #     useSsl: ~
  #     verify: ~
  #     verifyCertPath: ~
  #     endpointUrl: ~
  #     skipEmptyFiles: ~
  ##  Uncomment this configuration if the CustomComputeLogManager is selected.
  ##  Using this setting requires a custom Dagit image that defines the user specified
  ##  compute log manager in an installed python module.
  #   customComputeLogManager:
  #     module: ~
  #     class: ~
  #     config: {}

pythonLogs: {}
## The names of python loggers that will be captured as Dagster logs
#  managedPythonLoggers:
#    - foo_logger
## The log level for the instance. Logs emitted below this severity will be ignored.
## One of [NOTSET, DEBUG, INFO, WARNING, WARN, ERROR, FATAL, CRITICAL]
#  pythonLogLevel: INFO
## Python log handlers that will be applied to all Dagster logs
#  dagsterHandlerConfig:
#    handlers:
#      myHandler:
#        class: logging.FileHandler
#        filename: "/logs/my_dagster_logs.log"
#        mode: "a"

####################################################################################################
# User Code Deployments: Configuration for user code containers to be loaded via GRPC server. For
# each item in the "deployments" list, a K8s Deployment and K8s Service will be created to run the
# GRPC server that Dagit/Dagster communicates with to get repository information and the current
# image information. These deployments can be updated independently of Dagit, and Dagit/Dagster
# will pull the current image for all execution. When using a distributed executor (such as
# Celery-K8s) for pipeline run, the current image will be queried once and used for all
# solid executions for that pipeline run. In order to guarantee that all solid executions within a
# pipeline execution use the same image, we recommend using a unique tag (ie not "latest").
#
# All user code will be invoked within the images.
####################################################################################################
dagster-user-deployments:
  # Creates a workspace file with the gRPC servers hosting your user code.
  enabled: true

  # If you plan on deploying user code in a separate Helm release, set this to false.
  enableSubchart: true

  # Specify secrets to run user code server containers based on images in private registries. See:
  # https://kubernetes.io/docs/concepts/containers/images/#referring-to-an-imagepullsecrets-on-a-pod
  imagePullSecrets: []

  # List of unique deployments
  deployments:
    - name: "k8s-example-user-code-1"
      image:
        # When a tag is not supplied, it will default as the Helm chart version.
        repository: "docker.io/dagster/user-code-example"
        tag: ~

        # Change with caution! If you're using a fixed tag for pipeline run images, changing the
        # image pull policy to anything other than "Always" will use a cached/stale image, which is
        # almost certainly not what you want.
        pullPolicy: Always

      # Arguments to `dagster api grpc`.
      # Ex: "dagster api grpc -m dagster_test.test_project.test_pipelines.repo -a define_demo_execution_repo"
      # would translate to:
      # dagsterApiGrpcArgs:
      #   - "-m"
      #   - "dagster_test.test_project.test_pipelines.repo"
      #   - "-a"
      #   - "define_demo_execution_repo"
      dagsterApiGrpcArgs:
        - "--python-file"
        - "/example_project/example_repo/repo.py"
      port: 3030

      # Whether or not to include configuration specified for this user code deployment in the pods
      # launched for runs from that deployment
      includeConfigInLaunchedRuns:
        enabled: true

      # Additional environment variables to set.
      # A Kubernetes ConfigMap will be created with these environment variables. See:
      # https://kubernetes.io/docs/concepts/configuration/configmap/
      #
      # Example:
      #
      # env:
      #   ENV_ONE: one
      #   ENV_TWO: two
      env: {}

      # Additional environment variables can be retrieved and set from ConfigMaps. See:
      # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
      #
      # Example:
      #
      # envConfigMaps:
      #   - name: config-map
      envConfigMaps: []

      # Additional environment variables can be retrieved and set from Secrets. See:
      # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
      #
      # Example:
      #
      # envSecrets:
      #   - name: secret
      envSecrets: []

      # Additional labels that should be included. See:
      # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
      #
      # Example:
      # labels:
      #   my-label-key: my_label-value
      labels: {}

      # Additional volumes that should be included. See:
      # https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core
      #
      # Example:
      #
      # volumes:
      #   - name: my-volume
      #     configMap: my-config-map
      volumes: []

      # Additional volume mounts that should be included. See:
      # See: https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core
      #
      # Example:
      #
      # volumeMounts:
      #   - name: test-volume
      #     mountPath: /opt/dagster/test_folder
      #     subPath: test_file.yaml
      volumeMounts: []

      annotations: {}
      nodeSelector: {}
      affinity: {}
      tolerations: []
      podSecurityContext: {}
      securityContext: {}
      resources: {}
      # Readiness probe detects when the pod is ready to serve requests.
      # https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes
      readinessProbe:
        # If `readinessProbe` has no `exec` field, then the following default will be used:
        # exec:
        #   command: ["dagster", "api", "grpc-health-check", "-p", "{{ $deployment.port }}"]
        periodSeconds: 20
        timeoutSeconds: 3
        successThreshold: 1
        failureThreshold: 3

      # As of 0.14.0, liveness probes are disabled by default. If you want to enable them, it's recommended to also
      # enable startup probes.
      livenessProbe: {}
      startupProbe:
        enabled: false

      service:
        annotations: {}

####################################################################################################
# Pipeline Run: Configuration for user code containers.
#
# `DAGSTER_K8S_PIPELINE_RUN_IMAGE` environment variable will point to the image specified below.
# The run config for the celery executor can set `job_image` to fetch from environment variable
# `DAGSTER_K8S_PIPELINE_RUN_IMAGE`, so that celery workers will launch k8s jobs with said image.
#
####################################################################################################
pipelineRun:
  image:
    # When a tag is not supplied for a Dagster provided image,
    # it will default as the Helm chart version.
    repository: "docker.io/dagster/user-code-example"
    tag: ~
    pullPolicy: Always

  # Additional environment variables to set.
  # A Kubernetes ConfigMap will be created with these environment variables. See:
  # https://kubernetes.io/docs/concepts/configuration/configmap/
  #
  # Example:
  #
  # env:
  #   ENV_ONE: one
  #   ENV_TWO: two
  env: {}

####################################################################################################
# Scheduler: Configuration for the scheduler
####################################################################################################
scheduler:
  # Type can be one of [
  #   DagsterDaemonScheduler,
  #   CustomScheduler,
  #  ]
  type: DagsterDaemonScheduler

  config: {}
  ## Uncomment this configuration will only be used if the CustomScheduler is selected.
  ## Using this setting requires a custom Dagit image that defines the user specified
  ## scheduler in an installed python module.
  #   customScheduler:
  #     module: ~
  #     class: ~
  #     config: {}

####################################################################################################
# Run Launcher: Configuration for run launcher
####################################################################################################
runLauncher:
  # Type can be one of [K8sRunLauncher, CeleryK8sRunLauncher, CustomRunLauncher]
  type: K8sRunLauncher

  config:
    # This configuration will only be used if the K8sRunLauncher is selected
    k8sRunLauncher:
      # Change with caution! If you're using a fixed tag for pipeline run images, changing the
      # image pull policy to anything other than "Always" will use a cached/stale image, which is
      # almost certainly not what you want.
      imagePullPolicy: "Always"

      ## The image to use for the launched Job's Dagster container.
      ## The `pullPolicy` field is ignored. Use`imagePullPolicy` instead.
      # image:
      #   repository: ""
      #   tag: ""
      #   pullPolicy: Always

      # The K8s namespace where new jobs will be launched.
      # By default, the release namespace is used.
      jobNamespace: ~

      # Set to true to load kubeconfig from within cluster.
      loadInclusterConfig: true

      # File to load kubeconfig from. Only set this if loadInclusterConfig is false.
      kubeconfigFile: ~

      # Additional environment variables can be retrieved and set from ConfigMaps for the Job. See:
      # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
      #
      # Example:
      #
      # envConfigMaps:
      #   - name: config-map
      envConfigMaps: []

      # Additional environment variables can be retrieved and set from Secrets for the Job. See:
      # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
      #
      # Example:
      #
      # envSecrets:
      #   - name: secret
      envSecrets: []

      # Additional variables from the existing environment can be passed into the Job.
      #
      # Example:
      #
      # envVars:
      #   - "FOO_ENV_VAR" (Will pull the value of FOO_ENV_VAR from the calling process)
      #   - "BAR_ENV_VAR=baz_value" (Will set the value of BAR_ENV_VAR to baz_value)
      envVars: []

      # Additional volumes that should be included in the Job's Pod. See:
      # https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core
      #
      # Example:
      #
      # volumes:
      #   - name: my-volume
      #     configMap: my-config-map
      volumes: []

      # Additional volume mounts that should be included in the container in the Job's Pod. See:
      # See: https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core
      #
      # Example:
      #
      # volumeMounts:
      #   - name: test-volume
      #     mountPath: /opt/dagster/test_folder
      #     subPath: test_file.yaml
      volumeMounts: []

      # Additional labels that should be included in the Job's Pod. See:
      # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
      #
      # Example:
      # labels:
      #   my_label_key: my_label_value
      labels: {}

      # Default compute resource requirements for the container in the Job's Pod. See:
      # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers
      #
      # Example:
      # resources:
      #   limits:
      #     cpu: 100m
      #     memory: 128Mi
      #   requests:
      #     cpu: 100m
      #     memory: 128Mi
      resources: {}

      # Whether the launched Kubernetes Jobs and Pods should fail if the Dagster run fails.
      failPodOnRunFailure: false

    # This configuration will only be used if the CeleryK8sRunLauncher is selected
    celeryK8sRunLauncher:
      # Change with caution! If you're using a fixed tag for pipeline run images, changing the
      # image pull policy to anything other than "Always" will use a cached/stale image, which is
      # almost certainly not what you want.
      imagePullPolicy: "Always"

      # The Celery workers can be deployed with a fixed image (no user code included)
      image:
        # When a tag is not supplied for a Dagster provided image,
        # it will default as the Helm chart version.
        repository: "docker.io/dagster/dagster-celery-k8s"
        tag: ~
        pullPolicy: Always

      # Support overriding the name prefix of Celery worker pods
      nameOverride: "celery-workers"

      # Additional config options for Celery, applied to all queues.
      # These can be overridden per-queue below.
      # For available options, see:
      # https://docs.celeryq.dev/en/stable/userguide/configuration.html
      configSource: {}

      # Additional Celery worker queues can be configured here. When overriding, be sure to
      # provision a "dagster" worker queue, as this is the default queue used by Dagster.
      #
      # Optionally, labels and node selectors can be set on the Celery queue's workers.
      # Specifying a queue's node selector will override any existing node selector defaults.
      # configSource will be merged with the shared configSource above.
      workerQueues:
        - name: "dagster"
          replicaCount: 2
          labels: {}
          nodeSelector: {}
          configSource: {}
          additionalCeleryArgs: []

      # Additional environment variables to set on the celery/job containers
      # A Kubernetes ConfigMap will be created with these environment variables. See:
      # https://kubernetes.io/docs/concepts/configuration/configmap/
      #
      # Example:
      #
      # env:
      #   ENV_ONE: one
      #   ENV_TWO: two
      env: {}

      # Additional environment variables can be retrieved and set from ConfigMaps. See:
      # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
      #
      # Example:
      #
      # envConfigMaps:
      #   - name: config-map
      envConfigMaps: []

      # Additional environment variables can be retrieved and set from Secrets. See:
      # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
      #
      # Example:
      #
      # envSecrets:
      #   - name: secret
      envSecrets: []

      annotations: {}

      # Sets a node selector as a default for all Celery queues.
      #
      # See:
      # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
      nodeSelector: {}

      # Support affinity and tolerations for Celery pod assignment. See:
      # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
      # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
      affinity: {}
      tolerations: []
      podSecurityContext: {}
      securityContext: {}

      # Specify resources.
      # Example:
      #
      # resources:
      #   limits:
      #     cpu: 100m
      #     memory: 128Mi
      #   requests:
      #     cpu: 100m
      #     memory: 128Mi
      resources: {}

      # If `livenessProbe` does not contain `exec` field, then we will default to using:
      # exec:
      #   command:
      #     - /bin/sh
      #     - -c
      #     - dagster-celery status -A dagster_celery_k8s.app -y {{ $.Values.global.dagsterHome }}/celery-config.yaml | grep "${HOSTNAME}:.*OK"
      livenessProbe:
        initialDelaySeconds: 15
        periodSeconds: 10
        timeoutSeconds: 10
        successThreshold: 1
        failureThreshold: 3

      # Additional volumes that should be included in the Job's Pod. See:
      # https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core
      #
      # Example:
      #
      # volumes:
      #   - name: my-volume
      #     configMap: my-config-map
      volumes: []

      # Additional volume mounts that should be included in the container in the Job's Pod. See:
      # See: https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core
      #
      # Example:
      #
      # volumeMounts:
      #   - name: test-volume
      #     mountPath: /opt/dagster/test_folder
      #     subPath: test_file.yaml
      volumeMounts: []

      # Additional labels that should be included in the Job's Pod. See:
      # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
      #
      # Example:
      # labels:
      #   my_label_key: my_label_value
      labels: {}

      # Whether the launched Kubernetes Jobs and Pods should fail if the Dagster run fails.
      failPodOnRunFailure: false

    ## Uncomment this configuration will only be used if the CustomRunLauncher is selected.
    ## Using this setting requires a custom Dagit image that defines the user specified
    ## run launcher in an installed python module.
    # customRunLauncher:
    #   module: ~
    #   class: ~
    #   config: {}

####################################################################################################
# PostgreSQL: Configuration values for postgresql
#
# https://github.com/kubernetes/charts/blob/master/stable/postgresql/README.md
#
# A PostgreSQL database is required to run Dagster on Kubernetes. If postgresql.enabled is marked as
# false, the PG credentials specified here will still be used, and should point to an external PG
# database that is accessible from this chart.
####################################################################################################
postgresql:
  # set postgresql.enabled to be false to disable deploy of a PostgreSQL database and use an
  # existing external PostgreSQL database
  enabled: true

  # Used by init container to check that db is running. (Even if enabled:false)
  image:
    repository: "library/postgres"
    tag: "9.6.21"
    pullPolicy: IfNotPresent

  # set this PostgreSQL hostname when using an external PostgreSQL database
  postgresqlHost: ""

  postgresqlUsername: test

  # Note when changing this password (e.g. in test) that credentials will
  # persist as long as the PVCs do -- see:
  # https://github.com/helm/charts/issues/12836#issuecomment-524552358
  postgresqlPassword: test

  postgresqlDatabase: test

  # set postgresql parameter keywords for the connection string.
  # see: https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS
  postgresqlParams: {}

  # When set, overrides the default `postgresql` scheme for the connection string.
  # (e.g., set to `postgresql+pg8000` to use the `pg8000` library).
  # See: https://docs.sqlalchemy.org/en/13/dialects/postgresql.html#dialect-postgresql
  postgresqlScheme: ""

  service:
    port: 5432

# Whether to generate a secret resource for the PostgreSQL password. Useful if
# global.postgresqlSecretName is managed outside of this helm chart.
generatePostgresqlPasswordSecret: true

# If true, the helm chart will create a secret for you with the Celery broker and backend
# connection urls, including an optional Redis or RabbitMQ password. Set this to false if you want
# to manage a secret with the Celery broker/backend connection strings yourself. If you manage
# the secret yourself, the secret should have the name specified in global.celeryConfigSecretName,
# and should have the broker URL in a DAGSTER_CELERY_BROKER_URL key and the backend URL in a
# DAGSTER_CELERY_BACKEND_URL key.
generateCeleryConfigSecret: true

####################################################################################################
# RabbitMQ: Configuration values for rabbitmq. Only one of RabbitMQ / Redis should be enabled.
####################################################################################################
rabbitmq:
  enabled: false

  image:
    repository: "bitnami/rabbitmq"
    tag: "3.8.12"
    pullPolicy: IfNotPresent

  rabbitmq:
    username: test
    password: test

  service:
    port: 5672

  # https://github.com/helm/charts/issues/17250#issuecomment-533444837
  volumePermissions:
    enabled: true
    image:
      repository: bitnami/minideb
      tag: stretch
      pullPolicy: IfNotPresent

####################################################################################################
# Redis: Configuration values for Redis. Can be used instead of RabbitMQ.
####################################################################################################
redis:
  # To use redis instead of rabbitmq, set `enabled` to true.
  enabled: false

  # To manage redis via helm, set `internal` to `true`. To use an external redis, set `internal` to `false`.
  # Note: If `internal` is true, then redis pod will be created regardless of `enabled` flag.
  internal: false

  usePassword: false
  password: "test"

  # Redis host URL
  host: ""

  # Redis port
  port: 6379

  # Set DB number for Redis broker DB (default 0)
  brokerDbNumber: 0

  # Set DB number for Redis backend DB (default 0)
  backendDbNumber: 0

  # If your Redis connection needs configuration options, you can use this field to specific the
  # exact connection URL needed, rather than letting it be constructed from the Helm values.
  brokerUrl: ""
  backendUrl: ""

####################################################################################################
# Flower: (Optional) The flower web interface for diagnostics and debugging Celery queues & workers
####################################################################################################
flower:
  enabled: false

  image:
    repository: "docker.io/mher/flower"
    tag: "0.9.5"
    pullPolicy: Always

  service:
    type: ClusterIP
    annotations: {}
    port: 5555

  # Support Node, affinity and tolerations for Flower pod assignment. See:
  # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  annotations: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  podSecurityContext: {}
  securityContext: {}

  resources: {}
  # If you want to specify resources, uncomment the following lines, adjust them as necessary,
  # and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

  # Liveness probe detects when to restart flower.
  # https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes
  livenessProbe:
    tcpSocket:
      port: "flower"
    # initialDelaySeconds: 60
    periodSeconds: 20
    failureThreshold: 3

  # Startup probe (available in kubernetes v1.16+) is used at pod startup. Once it has succeeded,
  # then liveness probe takes over.
  # If on kubernetes < v1.16, then comment out `startupProbe` lines and comment in
  # `initialDelaySeconds: 60` under `livenessProbe`
  startupProbe:
    tcpSocket:
      port: "flower"
    periodSeconds: 10
    failureThreshold: 6

####################################################################################################
# Ingress: (Optional) Create ingresses for Dagit and Flower
####################################################################################################
ingress:
  enabled: false

  annotations: {}

  # Specify the IngressClass used to implement this ingress.
  #
  # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
  ingressClassName: ~

  dagit:
    # Ingress hostname for Dagit e.g. dagit.mycompany.com
    # This variable allows customizing the route pattern in the ingress. Some
    # ingress controllers may only support "/", whereas some may need "/*".
    # NOTE: Dagit doesn't yet support hosting on a path, e.g. mycompany.com/dagit.
    path: "/*"
    pathType: ImplementationSpecific
    # NOTE: do NOT keep trailing slash. For root configuration, set as empty string
    # See: https://github.com/dagster-io/dagster/issues/2073
    host: ""

    tls:
      enabled: false
      secretName: ""

    # Different http paths to add to the ingress before the default dagit path
    # Example:
    #
    # precedingPaths:
    #   - path: "/*"
    #     pathType: ImplementationSpecific
    #     serviceName: "ssl-redirect"
    #     servicePort: "use-annotation"
    precedingPaths: []

    # Different http paths to add to the ingress after the default dagit path
    # Example:
    #
    # succeedingPaths:
    #   - path: "/*"
    #     pathType: ImplementationSpecific
    #     serviceName: "ssl-redirect"
    #     servicePort: "use-annotation"
    succeedingPaths: []

  readOnlyDagit:
    # Ingress hostname for read only Dagit e.g. viewer.dagit.mycompany.com
    # This variable allows customizing the route pattern in the ingress. Some
    # ingress controllers may only support "/", whereas some may need "/*".
    # NOTE: Dagit doesn't yet support hosting on a path, e.g. mycompany.com/dagit.
    path: "/*"
    pathType: ImplementationSpecific
    # NOTE: do NOT keep trailing slash. For root configuration, set as empty string
    # See: https://github.com/dagster-io/dagster/issues/2073
    host: ""

    tls:
      enabled: false
      secretName: ""

    # Different http paths to add to the ingress before the default dagit path
    # Example:
    #
    # precedingPaths:
    #   - path: "/*"
    #     pathType: ImplementationSpecific
    #     serviceName: "ssl-redirect"
    #     servicePort: "use-annotation"
    precedingPaths: []

    # Different http paths to add to the ingress after the default dagit path
    # Example:
    #
    # succeedingPaths:
    #   - path: "/*"
    #     pathType: ImplementationSpecific
    #     serviceName: "ssl-redirect"
    #     servicePort: "use-annotation"
    succeedingPaths: []

  flower:
    # Ingress hostname for Flower e.g. flower.mycompany.com
    host: ""
    # if path is '/flower', Flower will be accessible at 'mycompany.com/flower'
    # NOTE: do NOT keep trailing slash. For root configuration, set as empty string
    path: ""
    pathType: ImplementationSpecific

    tls:
      enabled: false
      secretName: ""

    # Different http paths to add to the ingress before the default flower path
    # Example:
    #
    # precedingPaths:
    #   - path: "/*"
    #     pathType: ImplementationSpecific
    #     serviceName: "ssl-redirect"
    #     servicePort: "use-annotation"
    precedingPaths: []

    # Different http paths to add to the ingress after the default flower path
    # Example:
    #
    # succeedingPaths:
    #   - path: "/*"
    #     pathType: ImplementationSpecific
    #     serviceName: "ssl-redirect"
    #     servicePort: "use-annotation"
    succeedingPaths: []

####################################################################################################
# Dagster Daemon (Optional) Deploy a daemon for launching queued runs and running schedules and
# sensors.
#
# By default, this daemon is included in your deployment and used to run schedules and sensors.
# Setting `enabled` to false will stop the daemon from being included in your deployment.
#
# Each thread in the daemon periodically sends heartbeats to indicate that it is still running.
# Setting `heartbeatTolerance` lets you configure how long each thread can run without sending
# a heartbeat before the daemon determines that one must be hanging and restarts the process.
#
# Setting `config.queuedRunCoordinator.maxConcurrentRuns` in `runCoordinator` allows you to set
# limits on the total number of runs that can execute at once.
####################################################################################################
dagsterDaemon:
  enabled: true

  image:
    # When a tag is not supplied for a Dagster provided image,
    # it will default as the Helm chart version.
    repository: "docker.io/dagster/dagster-celery-k8s"
    tag: ~
    pullPolicy: Always

  heartbeatTolerance: 300

  runCoordinator:
    enabled: false

    # Type can be one of [
    #   QueuedRunCoordinator,
    #   CustomRunCoordinator,
    #  ]
    type: QueuedRunCoordinator
    config:
      queuedRunCoordinator:
        maxConcurrentRuns: ~
        tagConcurrencyLimits: []
        dequeueIntervalSeconds: ~

    ##  Uncomment this configuration if the CustomRunCoordinator is selected.
    ##  Using this setting requires a custom Daemon image that defines the user specified
    ##  run coordinator in an installed python module.
    #   customRunCoordinator:
    #     module: ~
    #     class: ~
    #     config: {}

  # Experimental feature to add fault tolerance to Dagster runs. The new Monitoring Daemon will
  # perform health checks on run workers. If a run doesn't start within the timeout, it will be
  # marked as failed. If a run had started but then the run worker crashed, the daemon will attempt
  # to resume the run with a new run worker.
  runMonitoring:
    enabled: false
    # Timeout for runs to start (avoids runs hanging in STARTED)
    startTimeoutSeconds: 180
    # How often to check on in progress runs
    pollIntervalSeconds: 120
    # Max number of times to attempt to resume a run with a new run worker. Defaults to 3 if the the
    # run launcher supports resuming runs, otherwise defaults to 0.
    maxResumeRunAttempts: ~

  # Additional environment variables to set.
  # A Kubernetes ConfigMap will be created with these environment variables. See:
  # https://kubernetes.io/docs/concepts/configuration/configmap/
  #
  # Example:
  #
  # env:
  #   ENV_ONE: one
  #   ENV_TWO: two
  env: {}

  # Additional environment variables can be retrieved and set from ConfigMaps. See:
  # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  #
  # Example:
  #
  # envConfigMaps:
  #   - name: config-map
  envConfigMaps: []

  # Additional environment variables can be retrieved and set from Secrets. See:
  # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
  #
  # Example:
  #
  # envSecrets:
  #   - name: secret
  envSecrets: []

  # Additional labels that should be included on the deployment. See:
  # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
  #
  # Example:
  # deploymentLabels:
  #   my-label-key: my_label-value
  deploymentLabels: {}

  # Additional labels that should be included on the pod. See:
  # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
  #
  # Example:
  # labels:
  #   my-label-key: my_label-value
  labels: {}

  annotations: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  podSecurityContext: {}
  securityContext: {}
  resources: {}

  # As of 0.14.0, liveness probes are disabled by default. If you want to enable them, it's recommended to also
  # enable startup probes.
  livenessProbe: {}
  readinessProbe: {}
  startupProbe: {}

####################################################################################################
# busybox: Configuration for the busybox image used to check connections
####################################################################################################
busybox:
  image:
    repository: "docker.io/busybox"
    tag: "1.28"
    pullPolicy: "IfNotPresent"

####################################################################################################
# Extra Manifests: (Optional) Create additional k8s resources within this chart
####################################################################################################
extraManifests:
#  # Set default container resource requests/limits for the namespace
#  #   * To override these for dagster system containers; edit the resources sections of
#  #     this values yaml -  eg: dagit.resources & celery.resources
#  #   * To override these in solid execution containers; add a @solid(tag=) similar to:
#  #      { "dagster-k8s/config": { "container_config": { "resources": {...
#  - apiVersion: v1
#    kind: LimitRange
#    metadata:
#      name: default-container-resources
#    spec:
#      limits:
#        - default:
#            cpu: 250m
#            memory: 512Mi
#          defaultRequest:
#            cpu: 100m
#            memory: 256Mi
#          type: Container
#  # Example 2:
#  - apiVersion: cloud.google.com/v1beta1
#    kind: BackendConfig
#    metadata:
#      name: "{{ .Release.Name }}-backend-config"
#      labels:
#      {{- include "dagster.labels" . | nindent 6 }}
#      spec:
#        securityPolicy:
#          name: "gcp-cloud-armor-policy-test"

####################################################################################################
# Dagster Instance Migrate: Creates a job to migrate your instance. This field should only be
# enabled in a one-off setting.
#
# For more details, see:
# https://docs.dagster.io/deployment/guides/kubernetes/how-to-migrate-your-instance
####################################################################################################
migrate:
  enabled: false

####################################################################################################
# As an open source project, we collect usage statistics to better understand how users engage
# with Dagster and to inform development priorities.
#
# Telemetry data will motivate projects such as adding functionality in frequently-used parts of
# the product and will help us understand adoption of new features.
#
# For more details, see:
# https://docs.dagster.io/getting-started/telemetry
####################################################################################################
telemetry:
  enabled: true

serviceAccount:
  create: true

  # Specifies the name for the service account to reference in the chart. Note that setting
  # the global service account name will override this field.
  name: ""

  annotations: {}
