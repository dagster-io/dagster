/**
 * THIS FILE IS GENERATED BY `yarn generate-integration-docs`.
 *
 * DO NOT EDIT MANUALLY.
 */

import {IntegrationFrontmatter} from '../types';
import dltLogo from './logos/dlthub.jpeg';

export const logo = dltLogo;

export const frontmatter: IntegrationFrontmatter = {
  id: 'dlt',
  status: 'published',
  name: 'dlt',
  title: 'Dagster & dlt',
  excerpt: 'Easily ingest and replicate data between systems with dlt through Dagster.',
  partnerlink: 'https://dlthub.com/',
  categories: ['ETL'],
  enabledBy: [],
  enables: [],
  tags: ['dagster-supported', 'etl'],
};

export const content =
  'This integration allows you to use [dlt](https://dlthub.com/) to easily ingest and replicate data between systems through Dagster.\n\n### Installation\n\n```bash\npip install dagster-dlt\n```\n\n### Example\n\n<CodeExample path="docs_snippets/docs_snippets/integrations/dlt.py" language="python" />\n\n:::note\n\nIf you are using the [sql_database](https://dlthub.com/docs/api_reference/dlt/sources/sql_database/__init__) source, consider setting `defer_table_reflect=True` to reduce database reads. By default, the Dagster daemon will refresh definitions roughly every minute, which will query the database for resource definitions.\n\n:::\n\n### About dlt\n\n[Data Load Tool (dlt)](https://dlthub.com/) is an open source library for creating efficient data pipelines. It offers features like secret management, data structure conversion, incremental updates, and pre-built sources and destinations, simplifying the process of loading messy data into well-structured datasets.';
