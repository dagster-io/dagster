/**
 * THIS FILE IS GENERATED BY `yarn generate-integration-docs`.
 *
 * DO NOT EDIT MANUALLY.
 */

import {IntegrationFrontmatter} from '../types';
import deltalakeLogo from './logos/deltalake.svg';

export const logo = deltalakeLogo;

export const frontmatter: IntegrationFrontmatter = {
  id: 'deltalake',
  status: 'published',
  name: 'Delta Lake',
  title: 'Dagster & Delta Lake',
  excerpt: 'Integrate your pipelines into Delta Lake.',
  partnerlink: 'https://delta.io/',
  categories: ['Storage'],
  enabledBy: [],
  enables: [],
  tags: ['community-supported', 'storage'],
};

export const content =
  'Delta Lake is a great storage format for Dagster workflows. With this integration, you can use the Delta Lake I/O Manager to read and write your Dagster assets.\n\nHere are some of the benefits that Delta Lake provides Dagster users:\n\n- Native PyArrow integration for lazy computation of large datasets\n- More efficient querying with file skipping with Z Ordering and liquid clustering\n- Built-in vacuuming to remove unnecessary files and versions\n- ACID transactions for reliable writes\n- Smooth versioning integration (versions can be use to trigger downstream updates).\n- Surfacing table stats based on the file statistics\n\n### Installation\n\n```bash\npip install dagster-deltalake\npip install dagster-deltalake-pandas\npip install dagster-deltalake-polars\n```\n\n### About Delta Lake\n\nDelta Lake is an open source storage framework that enables building a Lakehouse architecture with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs for Scala, Java, Rust, and Python.';
