import sys

from pyspark import SparkFiles
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate() # type: ignore
sc = spark.sparkContext
sys.path.insert(0, SparkFiles.getRootDirectory())

from dagster.utils.test import execute_solid_within_pipeline

from {pipeline_file} import {pipeline_fn_name}

if __name__ == '__main__':
    execute_solid_within_pipeline(
        {pipeline_fn_name},
        '{solid_name}',
        mode='{mode_name}',
        run_config={run_config},
    )