# serializer version: 1
# name: TestDynamicCommandExecution.test_command_execution[agent_error_agent_not_found_json]
  '''
  {"error": "Agent with ID 'nonexistent-agent-uuid' not found"}
  {"error": "Agent not found: nonexistent-agent-uuid"}
  Error: Failed to get agent: Agent not found: nonexistent-agent-uuid
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_error_agent_not_found_text_text]
  '''
  Agent with ID 'nonexistent-agent-uuid' not found
  Error querying Dagster Plus API: Agent not found: nonexistent-agent-uuid
  Error: Failed to get agent: Agent not found: nonexistent-agent-uuid
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_error_malformed_agent_id_json]
  '''
  {"error": "Agent with ID '''' not found"}
  {"error": "Agent not found: ''"}
  Error: Failed to get agent: Agent not found: ''
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_error_malformed_agent_id_text_text]
  '''
  Agent with ID '''' not found
  Error querying Dagster Plus API: Agent not found: ''
  Error: Failed to get agent: Agent not found: ''
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_agent_version_metadata_json]
  dict({
    'agent_label': None,
    'id': 'da7da2bb-33eb-4ce1-93ef-1a92e6737236',
    'last_heartbeat_time': 1758118915.5946717,
    'metadata': list([
      dict({
        'key': 'version',
        'value': '"1.5.1"',
      }),
      dict({
        'key': 'type',
        'value': '"K8sUserCodeLauncher"',
      }),
      dict({
        'key': 'queues',
        'value': '["default queue"]',
      }),
    ]),
    'status': 'RUNNING',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_agent_with_metadata_json]
  dict({
    'agent_label': None,
    'id': '858fd654-d0b5-477c-ac1a-c63db56246b7',
    'last_heartbeat_time': 1758118924.6589644,
    'metadata': list([
      dict({
        'key': 'utilization_metrics',
        'value': '{}',
      }),
      dict({
        'key': 'version',
        'value': '"1.11.10"',
      }),
      dict({
        'key': 'type',
        'value': '"K8sUserCodeLauncher"',
      }),
      dict({
        'key': 'queues',
        'value': '["default queue"]',
      }),
    ]),
    'status': 'RUNNING',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_agent_without_label_text_text]
  '''
  Label: Agent da7da2bb
  ID: da7da2bb-33eb-4ce1-93ef-1a92e6737236
  Status: RUNNING
  Last Heartbeat: 2025-09-17 14:21:55
  
  Metadata:
    version: "1.5.1"
    type: "K8sUserCodeLauncher"
    queues: ["default queue"]
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_multiple_agents_json]
  dict({
    'items': list([
      dict({
        'agent_label': None,
        'id': '858fd654-d0b5-477c-ac1a-c63db56246b7',
        'last_heartbeat_time': 1758118924.6589644,
        'metadata': list([
          dict({
            'key': 'utilization_metrics',
            'value': '{}',
          }),
          dict({
            'key': 'version',
            'value': '"1.11.10"',
          }),
          dict({
            'key': 'type',
            'value': '"K8sUserCodeLauncher"',
          }),
          dict({
            'key': 'queues',
            'value': '["default queue"]',
          }),
        ]),
        'status': 'RUNNING',
      }),
      dict({
        'agent_label': None,
        'id': 'da7da2bb-33eb-4ce1-93ef-1a92e6737236',
        'last_heartbeat_time': 1758118915.5946717,
        'metadata': list([
          dict({
            'key': 'version',
            'value': '"1.5.1"',
          }),
          dict({
            'key': 'type',
            'value': '"K8sUserCodeLauncher"',
          }),
          dict({
            'key': 'queues',
            'value': '["default queue"]',
          }),
        ]),
        'status': 'RUNNING',
      }),
    ]),
    'total': 2,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_multiple_agents_text_text]
  '''
  Label: Agent 858fd654
  ID: 858fd654-d0b5-477c-ac1a-c63db56246b7
  Status: RUNNING
  Last Heartbeat: 2025-09-17 14:22:04
  
  Label: Agent da7da2bb
  ID: da7da2bb-33eb-4ce1-93ef-1a92e6737236
  Status: RUNNING
  Last Heartbeat: 2025-09-17 14:21:55
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_running_agent_json]
  dict({
    'agent_label': None,
    'id': '858fd654-d0b5-477c-ac1a-c63db56246b7',
    'last_heartbeat_time': 1758118924.6589644,
    'metadata': list([
      dict({
        'key': 'utilization_metrics',
        'value': '{}',
      }),
      dict({
        'key': 'version',
        'value': '"1.11.10"',
      }),
      dict({
        'key': 'type',
        'value': '"K8sUserCodeLauncher"',
      }),
      dict({
        'key': 'queues',
        'value': '["default queue"]',
      }),
    ]),
    'status': 'RUNNING',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_running_agent_text_text]
  '''
  Label: Agent 858fd654
  ID: 858fd654-d0b5-477c-ac1a-c63db56246b7
  Status: RUNNING
  Last Heartbeat: 2025-09-17 14:22:04
  
  Metadata:
    utilization_metrics: {}
    version: "1.11.10"
    type: "K8sUserCodeLauncher"
    queues: ["default queue"]
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_second_agent_json_json]
  dict({
    'agent_label': None,
    'id': 'da7da2bb-33eb-4ce1-93ef-1a92e6737236',
    'last_heartbeat_time': 1758118915.5946717,
    'metadata': list([
      dict({
        'key': 'version',
        'value': '"1.5.1"',
      }),
      dict({
        'key': 'type',
        'value': '"K8sUserCodeLauncher"',
      }),
      dict({
        'key': 'queues',
        'value': '["default queue"]',
      }),
    ]),
    'status': 'RUNNING',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_second_agent_text_text]
  '''
  Label: Agent da7da2bb
  ID: da7da2bb-33eb-4ce1-93ef-1a92e6737236
  Status: RUNNING
  Last Heartbeat: 2025-09-17 14:21:55
  
  Metadata:
    version: "1.5.1"
    type: "K8sUserCodeLauncher"
    queues: ["default queue"]
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_single_agent_json]
  dict({
    'agent_label': None,
    'id': '858fd654-d0b5-477c-ac1a-c63db56246b7',
    'last_heartbeat_time': 1758118924.6589644,
    'metadata': list([
      dict({
        'key': 'utilization_metrics',
        'value': '{}',
      }),
      dict({
        'key': 'version',
        'value': '"1.11.10"',
      }),
      dict({
        'key': 'type',
        'value': '"K8sUserCodeLauncher"',
      }),
      dict({
        'key': 'queues',
        'value': '["default queue"]',
      }),
    ]),
    'status': 'RUNNING',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[agent_success_single_agent_text_text]
  '''
  Label: Agent 858fd654
  ID: 858fd654-d0b5-477c-ac1a-c63db56246b7
  Status: RUNNING
  Last Heartbeat: 2025-09-17 14:22:04
  
  Metadata:
    utilization_metrics: {}
    version: "1.11.10"
    type: "K8sUserCodeLauncher"
    queues: ["default queue"]
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_error_asset_not_found_json]
  '''
  {"error": "Asset not found: nonexistent-asset"}
  Error: Failed to get asset: Asset not found: nonexistent-asset
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_error_asset_not_found_status_view_json]
  '''
  {"error": "Asset not found: nonexistent-asset"}
  Error: Failed to get asset: Asset not found: nonexistent-asset
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_error_invalid_view_json]
  '''
  Usage: dg api asset get [OPTIONS] ASSET_KEY
  Try 'dg api asset get -h' for help.
  
  Error: Invalid value for '--view': 'invalid' is not 'status'.
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_error_malformed_asset_key_json]
  '''
  {"error": "Asset not found: ''"}
  Error: Failed to get asset: Asset not found: ''
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_assets_status_view_human_readable_text]
  '''
  Asset Key: ANALYTICS/company_perf
  ID: ["ANALYTICS", "company_perf"]
  Description: dbt model for: company_perf 
   
  	select
  	        company,
  	        sum(n_orders) as n_orders,
  	        sum(total_revenue) as total_revenue
  	from {{ ref("company_stats") }}
  	group by 1
  Group: ANALYTICS
  Kinds: dbt, snowflake
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: HEALTHY
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-09-09 00:02:25
  Latest Run ID: 83112ac7-a739-4b79-8f1f-6d91911a029a
  
  Asset Key: ANALYTICS/company_stats
  ID: ["ANALYTICS", "company_stats"]
  Description: dbt model for: company_stats 
   
  	{{
  	        config(tags=["core_kpis"])
  	}}
  	select
  	        order_date,
  	        company,
  	        count(*) as n_orders,
  	        sum(order_total) as total_revenue
  	from {{ ref("orders_augmented") }}
  	group by 1, 2
  Group: ANALYTICS
  Kinds: dbt, snowflake
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: HEALTHY
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-09-10 16:21:19
  Latest Run ID: a484f830-3007-424b-862e-4fefbd733bab
  
  Asset Key: ANALYTICS/order_stats
  ID: ["ANALYTICS", "order_stats"]
  Description: dbt model for: order_stats 
   
  	select
  	        {{ date_trunc("day", "order_date") }} as order_date,
  	        count(*) as n_orders,
  	        sum(order_total) as total_revenue
  	from {{ ref("orders_augmented") }}
  	{% if is_incremental() %}
  	WHERE {{ date_trunc("day", "order_date") }} >=  '{{ var('min_date') }}' AND {{ date_trunc("day", "order_date") }} <=  '{{ var('max_date') }}'
  	{% endif %}
  	group by 1
  Group: ANALYTICS
  Kinds: dbt, snowflake
  Asset Health: WARNING
  Materialization Status: HEALTHY
  Freshness Status: WARNING
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-09-07 00:03:22
  Latest Run ID: 112a4461-789e-477b-a88c-872cf8c24316
  Latest Partition: 2025-08-31
  
  Asset Key: ANALYTICS/orders_augmented
  ID: ["ANALYTICS", "orders_augmented"]
  Description: dbt model for: orders_augmented 
   
  	{{
  	        config(tags=["core_kpis"])
  	}}
  	select
  	        o.*,
  	        u.company,
  	        l.state,
  	        l.zip_code
  	from {{ ref("orders_cleaned") }} o 
  
  	left join {{ ref("users_cleaned") }} u
  	       on o.user_id = u.user_id
  
  	 left join {{ ref("locations_cleaned") }} l
  	        on o.user_id = l.user_id
  
  	{% if is_incremental() %}
  	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
  	{% endif %}
  Group: ANALYTICS
  Kinds: dbt, snowflake
  Asset Health: DEGRADED
  Materialization Status: DEGRADED
  Freshness Status: WARNING
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-09-10 00:02:11
  Latest Run ID: 085aa81e-11f7-4848-8e25-8b9e37b3a753
  Latest Partition: 2025-09-09
  
  Asset Key: ANALYTICS/sku_stats
  ID: ["ANALYTICS", "sku_stats"]
  Description: dbt model for: sku_stats 
   
  	select
  	        order_date,
  	        sku,
  	        count(*) as n_orders,
  	        sum(order_total) as total_revenue
  	from {{ ref("orders_augmented") }}
  	group by 1, 2
  Group: ANALYTICS
  Kinds: dbt, snowflake
  Asset Health: DEGRADED
  Materialization Status: HEALTHY
  Freshness Status: DEGRADED
  Asset Checks Status: WARNING
  Latest Materialization: 2025-09-01 00:03:55
  Latest Run ID: 41b0e33d-a965-423f-acca-b444a7058dba
  Total Checks: 1
  Warning Checks: 1
  
  Asset Key: ANALYTICS/weekly_order_summary
  ID: ["ANALYTICS", "weekly_order_summary"]
  Description: dbt model for: weekly_order_summary 
   
  	{{
  	        config(
  	                tags=["core_kpis"]
  	        )
  	}}
  
  	select
  	        order_date,
  	        n_orders as num_orders
  	from {{ ref("order_stats") }}
  	{% if is_incremental() %}
  	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
  	{% endif %}
  Group: ANALYTICS
  Kinds: dbt, snowflake
  Asset Health: WARNING
  Materialization Status: HEALTHY
  Freshness Status: WARNING
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-09-07 00:03:23
  Latest Run ID: 112a4461-789e-477b-a88c-872cf8c24316
  Latest Partition: 2025-08-31
  
  Asset Key: CLEANED/locations_cleaned
  ID: ["CLEANED", "locations_cleaned"]
  Description: dbt model for: locations_cleaned 
   
  	with source as (
      
  	select *
  	from {{ source("raw_data", "locations") }}
  
  	),
   
  	source_renamed as (
  
  	    select l_user_id as user_id,
  	           l_street_address as street_address,
  	           l_state as state,
  	           l_country as country,
  	           l_zip_code as zip_code,
  	           _sling_loaded_at
  	    from source
  
  	)
  
  	select *
  	from source_renamed
  Group: CLEANED
  Kinds: dbt, snowflake
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: HEALTHY
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-09-10 19:21:44
  Latest Run ID: 7bfdcc2b-d67d-4df8-bea0-3cf8d19e80eb
  
  Asset Key: CLEANED/orders_cleaned
  ID: ["CLEANED", "orders_cleaned"]
  Description: dbt model for: orders_cleaned 
   
  	{{config(tags="my_test_tag")}}
  	select
  	        user_id,
  	        quantity,
  	        purchase_price,
  	        sku,
  	        dt,
  	        cast(dt as datetime) as order_date,
  	        quantity * purchase_price as order_total
  	from {{ source("raw_data", "orders") }}
  	{% if is_incremental() %}
  	WHERE dt >= '{{ var('min_date') }}' AND dt <= '{{ var('max_date') }}'
  	{% endif %}
  Group: CLEANED
  Kinds: dbt, snowflake
  Asset Health: WARNING
  Materialization Status: HEALTHY
  Freshness Status: HEALTHY
  Asset Checks Status: WARNING
  Latest Materialization: 2025-09-10 19:21:02
  Latest Run ID: 198d2c64-664d-4b23-9c69-976247ac0c2d
  Latest Partition: 2025-09-09
  Total Checks: 4
  Warning Checks: 2
  
  Asset Key: CLEANED/users_cleaned
  ID: ["CLEANED", "users_cleaned"]
  Description: dbt model for: users_cleaned 
   
  	select
  	        user_id,
  	        created_at,
  	        company
  	from {{ source("raw_data", "users") }}
  	where not is_test_user
  Group: CLEANED
  Kinds: dbt, snowflake
  Asset Health: DEGRADED
  Materialization Status: DEGRADED
  Freshness Status: HEALTHY
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-09-10 19:21:02
  Latest Run ID: 198d2c64-664d-4b23-9c69-976247ac0c2d
  Latest Partition: 2025-09-09
  
  Asset Key: FORECASTING/big_orders
  ID: ["FORECASTING", "big_orders"]
  Description: Days where predicted orders surpass our current carrying capacity
  Group: FORECASTING
  Kinds: databricks, pyspark
  Asset Health: DEGRADED
  Materialization Status: DEGRADED
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2023-04-05 16:27:28
  Latest Run ID: db0cf46a-14b3-4f79-80f6-6961f2d4fb03
  
  Asset Key: FORECASTING/predicted_orders
  ID: ["FORECASTING", "predicted_orders"]
  Description: Predicted orders for the next 30 days based on the fit paramters
  Group: FORECASTING
  Kinds: pandas, snowflake
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-09-10 00:03:05
  Latest Run ID: 2b2e7e49-0093-425c-bdd4-404839306665
  
  Asset Key: MARKETING/avg_orders
  ID: ["MARKETING", "avg_orders"]
  Description: Computes avg order KPI, must be updated regularly for exec dashboard
  Group: MARKETING
  Kinds: pandas, snowflake
  Asset Health: DEGRADED
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: DEGRADED
  Latest Materialization: 2025-09-09 00:02:45
  Latest Run ID: 83112ac7-a739-4b79-8f1f-6d91911a029a
  Total Checks: 2
  Failed Checks: 1
  Warning Checks: 0
  
  Asset Key: MARKETING/key_product_deepdive
  ID: ["MARKETING", "key_product_deepdive"]
  Description: Creates a file for a BI tool based on the current quarters top product, represented as a dynamic partition
  Group: MARKETING
  Kinds: pandas, s3
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-08-26 20:39:09
  Latest Run ID: 7fd31e6d-e9a6-43c8-8a5e-a70873dffec5
  Latest Partition: macaroni
  
  Asset Key: MARKETING/min_order
  ID: ["MARKETING", "min_order"]
  Description: Computes min order KPI
  Group: MARKETING
  Kinds: pandas, snowflake
  Asset Health: DEGRADED
  Materialization Status: HEALTHY
  Freshness Status: DEGRADED
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-09-05 14:54:48
  Latest Run ID: f24fab3c-27e7-4a90-8b06-5bd7f454b7e5
  
  Asset Key: RAW_DATA/locations
  ID: ["RAW_DATA", "locations"]
  Description: None
  Group: RAW_DATA
  Kinds: SNOWFLAKE, sling
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-09-10 19:20:40
  Latest Run ID: 630a0162-dbd5-4bf7-b888-9a6cbefa0e9d
  
  Asset Key: RAW_DATA/orders
  ID: ["RAW_DATA", "orders"]
  Description: A table containing all orders that have been placed
  Group: RAW_DATA
  Kinds: api, snowflake
  Asset Health: DEGRADED
  Materialization Status: DEGRADED
  Freshness Status: HEALTHY
  Asset Checks Status: WARNING
  Latest Materialization: 2025-09-10 19:20:27
  Latest Run ID: 198d2c64-664d-4b23-9c69-976247ac0c2d
  Latest Partition: 2025-09-09
  Total Checks: 1
  Warning Checks: 1
  
  Asset Key: RAW_DATA/users
  ID: ["RAW_DATA", "users"]
  Description: A table containing all users data
  Group: RAW_DATA
  Kinds: api, snowflake
  Asset Health: DEGRADED
  Materialization Status: DEGRADED
  Freshness Status: HEALTHY
  Asset Checks Status: WARNING
  Latest Materialization: 2025-09-10 19:20:23
  Latest Run ID: 198d2c64-664d-4b23-9c69-976247ac0c2d
  Latest Partition: 2025-09-09
  Total Checks: 2
  Warning Checks: 2
  
  Asset Key: change_model
  ID: ["change_model"]
  Description: None
  Group: default
  Kinds: Kubernetes, S3
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-05-28 18:47:22
  Latest Run ID: b0b7679c-5180-4bc1-b7d7-27a12047f01f
  
  Asset Key: continent_stats
  ID: ["continent_stats"]
  Description: None
  Group: default
  Kinds: Kubernetes, S3
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-05-28 18:47:30
  Latest Run ID: b0b7679c-5180-4bc1-b7d7-27a12047f01f
  
  Asset Key: country_stats
  ID: ["country_stats"]
  Description: None
  Group: default
  Kinds: Kubernetes, S3
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: HEALTHY
  Latest Materialization: 2025-05-28 18:47:12
  Latest Run ID: b0b7679c-5180-4bc1-b7d7-27a12047f01f
  
  Asset Key: databricks/economic_indicators
  ID: ["databricks", "economic_indicators"]
  Description: Ledger loaded 
  Group: ingestion
  Kinds: databricks
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-09-10 12:00:46
  Latest Run ID: 26c59dcc-3484-4165-b281-e5254632ed4d
  
  Asset Key: databricks/news_sentiment
  ID: ["databricks", "news_sentiment"]
  Description: Ledger loaded 
  Group: ingestion
  Kinds: databricks
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-09-10 12:00:46
  Latest Run ID: 26c59dcc-3484-4165-b281-e5254632ed4d
  
  Asset Key: databricks/revenue
  ID: ["databricks", "revenue"]
  Description: Ledger loaded 
  Group: ingestion
  Kinds: databricks
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-09-10 12:00:50
  Latest Run ID: 26c59dcc-3484-4165-b281-e5254632ed4d
  
  Asset Key: databricks_asset
  ID: ["databricks_asset"]
  Description: None
  Group: FORECASTING
  Kinds: databricks, pyspark
  Asset Health: HEALTHY
  Materialization Status: HEALTHY
  Freshness Status: NOT_APPLICABLE
  Asset Checks Status: NOT_APPLICABLE
  Latest Materialization: 2025-05-28 18:52:32
  Latest Run ID: d5a01d8f-696e-4b7f-b1b3-351152bcf99d
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_assets_status_view_json]
  dict({
    'cursor': '["dbt", "model", "salesforce_source", "stg_salesforce__account_tmp"]',
    'has_more': True,
    'items': list([
      dict({
        'asset_key': 'ANALYTICS/company_perf',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_perf',
        ]),
        'description': '''
          dbt model for: company_perf 
           
          	select
          	        company,
          	        sum(n_orders) as n_orders,
          	        sum(total_revenue) as total_revenue
          	from {{ ref("company_stats") }}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "company_perf"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_perf',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_perf',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '83112ac7-a739-4b79-8f1f-6d91911a029a',
            'timestamp': 1757376145523.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/company_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_stats',
        ]),
        'description': '''
          dbt model for: company_stats 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        order_date,
          	        company,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "company_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'a484f830-3007-424b-862e-4fefbd733bab',
            'timestamp': 1757521279949.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/order_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'order_stats',
        ]),
        'description': '''
          dbt model for: order_stats 
           
          	select
          	        {{ date_trunc("day", "order_date") }} as order_date,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	{% if is_incremental() %}
          	WHERE {{ date_trunc("day", "order_date") }} >=  '{{ var('min_date') }}' AND {{ date_trunc("day", "order_date") }} <=  '{{ var('max_date') }}'
          	{% endif %}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "order_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.order_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.order_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'WARNING',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'WARNING',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-08-31',
            'run_id': '112a4461-789e-477b-a88c-872cf8c24316',
            'timestamp': 1757203402552.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/orders_augmented',
        'asset_key_parts': list([
          'ANALYTICS',
          'orders_augmented',
        ]),
        'description': '''
          dbt model for: orders_augmented 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        o.*,
          	        u.company,
          	        l.state,
          	        l.zip_code
          	from {{ ref("orders_cleaned") }} o 
          
          	left join {{ ref("users_cleaned") }} u
          	       on o.user_id = u.user_id
          
          	 left join {{ ref("locations_cleaned") }} l
          	        on o.user_id = l.user_id
          
          	{% if is_incremental() %}
          	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "orders_augmented"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'WARNING',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-09-09',
            'run_id': '085aa81e-11f7-4848-8e25-8b9e37b3a753',
            'timestamp': 1757462531632.0,
          }),
          'materialization_status': 'DEGRADED',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/sku_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'sku_stats',
        ]),
        'description': '''
          dbt model for: sku_stats 
           
          	select
          	        order_date,
          	        sku,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "sku_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'WARNING',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': 1,
            'status': 'WARNING',
            'total_num_checks': 1,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'DEGRADED',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '41b0e33d-a965-423f-acca-b444a7058dba',
            'timestamp': 1756685035863.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/weekly_order_summary',
        'asset_key_parts': list([
          'ANALYTICS',
          'weekly_order_summary',
        ]),
        'description': '''
          dbt model for: weekly_order_summary 
           
          	{{
          	        config(
          	                tags=["core_kpis"]
          	        )
          	}}
          
          	select
          	        order_date,
          	        n_orders as num_orders
          	from {{ ref("order_stats") }}
          	{% if is_incremental() %}
          	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "weekly_order_summary"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.weekly_order_summary',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.weekly_order_summary',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'WARNING',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'WARNING',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-08-31',
            'run_id': '112a4461-789e-477b-a88c-872cf8c24316',
            'timestamp': 1757203403541.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'CLEANED/locations_cleaned',
        'asset_key_parts': list([
          'CLEANED',
          'locations_cleaned',
        ]),
        'description': '''
          dbt model for: locations_cleaned 
           
          	with source as (
              
          	select *
          	from {{ source("raw_data", "locations") }}
          
          	),
           
          	source_renamed as (
          
          	    select l_user_id as user_id,
          	           l_street_address as street_address,
          	           l_state as state,
          	           l_country as country,
          	           l_zip_code as zip_code,
          	           _sling_loaded_at
          	    from source
          
          	)
          
          	select *
          	from source_renamed
        ''',
        'group_name': 'CLEANED',
        'id': '["CLEANED", "locations_cleaned"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.locations_cleaned',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.locations_cleaned',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '7bfdcc2b-d67d-4df8-bea0-3cf8d19e80eb',
            'timestamp': 1757532104423.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'CLEANED/orders_cleaned',
        'asset_key_parts': list([
          'CLEANED',
          'orders_cleaned',
        ]),
        'description': '''
          dbt model for: orders_cleaned 
           
          	{{config(tags="my_test_tag")}}
          	select
          	        user_id,
          	        quantity,
          	        purchase_price,
          	        sku,
          	        dt,
          	        cast(dt as datetime) as order_date,
          	        quantity * purchase_price as order_total
          	from {{ source("raw_data", "orders") }}
          	{% if is_incremental() %}
          	WHERE dt >= '{{ var('min_date') }}' AND dt <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'CLEANED',
        'id': '["CLEANED", "orders_cleaned"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.orders_cleaned',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'dt',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.orders_cleaned',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'WARNING',
          'asset_health': 'WARNING',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': 2,
            'status': 'WARNING',
            'total_num_checks': 4,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-09-09',
            'run_id': '198d2c64-664d-4b23-9c69-976247ac0c2d',
            'timestamp': 1757532062078.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'CLEANED/users_cleaned',
        'asset_key_parts': list([
          'CLEANED',
          'users_cleaned',
        ]),
        'description': '''
          dbt model for: users_cleaned 
           
          	select
          	        user_id,
          	        created_at,
          	        company
          	from {{ source("raw_data", "users") }}
          	where not is_test_user
        ''',
        'group_name': 'CLEANED',
        'id': '["CLEANED", "users_cleaned"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.users_cleaned',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'created_at',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.users_cleaned',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-09-09',
            'run_id': '198d2c64-664d-4b23-9c69-976247ac0c2d',
            'timestamp': 1757532062400.0,
          }),
          'materialization_status': 'DEGRADED',
        }),
      }),
      dict({
        'asset_key': 'FORECASTING/big_orders',
        'asset_key_parts': list([
          'FORECASTING',
          'big_orders',
        ]),
        'description': 'Days where predicted orders surpass our current carrying capacity',
        'group_name': 'FORECASTING',
        'id': '["FORECASTING", "big_orders"]',
        'kinds': list([
          'databricks',
          'pyspark',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'intValue': 50,
            'label': 'resource_constrained_at',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'db0cf46a-14b3-4f79-80f6-6961f2d4fb03',
            'timestamp': 1680712048768.0,
          }),
          'materialization_status': 'DEGRADED',
        }),
      }),
      dict({
        'asset_key': 'FORECASTING/predicted_orders',
        'asset_key_parts': list([
          'FORECASTING',
          'predicted_orders',
        ]),
        'description': 'Predicted orders for the next 30 days based on the fit paramters',
        'group_name': 'FORECASTING',
        'id': '["FORECASTING", "predicted_orders"]',
        'kinds': list([
          'pandas',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '2b2e7e49-0093-425c-bdd4-404839306665',
            'timestamp': 1757462585599.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'MARKETING/avg_orders',
        'asset_key_parts': list([
          'MARKETING',
          'avg_orders',
        ]),
        'description': 'Computes avg order KPI, must be updated regularly for exec dashboard',
        'group_name': 'MARKETING',
        'id': '["MARKETING", "avg_orders"]',
        'kinds': list([
          'pandas',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'DEGRADED',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': 1,
            'num_warning_checks': 0,
            'status': 'DEGRADED',
            'total_num_checks': 2,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '83112ac7-a739-4b79-8f1f-6d91911a029a',
            'timestamp': 1757376165289.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'MARKETING/key_product_deepdive',
        'asset_key_parts': list([
          'MARKETING',
          'key_product_deepdive',
        ]),
        'description': 'Creates a file for a BI tool based on the current quarters top product, represented as a dynamic partition',
        'group_name': 'MARKETING',
        'id': '["MARKETING", "key_product_deepdive"]',
        'kinds': list([
          'pandas',
          's3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': 'macaroni',
            'run_id': '7fd31e6d-e9a6-43c8-8a5e-a70873dffec5',
            'timestamp': 1756240749936.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'MARKETING/min_order',
        'asset_key_parts': list([
          'MARKETING',
          'min_order',
        ]),
        'description': 'Computes min order KPI',
        'group_name': 'MARKETING',
        'id': '["MARKETING", "min_order"]',
        'kinds': list([
          'pandas',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'DEGRADED',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'f24fab3c-27e7-4a90-8b06-5bd7f454b7e5',
            'timestamp': 1757084088986.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'RAW_DATA/locations',
        'asset_key_parts': list([
          'RAW_DATA',
          'locations',
        ]),
        'description': None,
        'group_name': 'RAW_DATA',
        'id': '["RAW_DATA", "locations"]',
        'kinds': list([
          'SNOWFLAKE',
          'sling',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'jsonString': '{"object": "locations"}',
            'label': 'stream_config',
          }),
          dict({
            'description': None,
            'label': 'dagster_sling/dagster_sling_translator',
            'text': '[CustomSlingTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'jsonString': '{"defaults": {"mode": "full-refresh", "object": "{stream_file_folder}.{stream_file_name}", "source_options": {"format": "csv"}}, "source": "S3", "streams": {"s3://hooli-demo/embedded-elt/locations.csv": {"object": "locations"}}, "target": "SNOWFLAKE_PROD"}',
            'label': 'dagster_sling/sling_replication_config',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '630a0162-dbd5-4bf7-b888-9a6cbefa0e9d',
            'timestamp': 1757532040442.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'RAW_DATA/orders',
        'asset_key_parts': list([
          'RAW_DATA',
          'orders',
        ]),
        'description': 'A table containing all orders that have been placed',
        'group_name': 'RAW_DATA',
        'id': '["RAW_DATA", "orders"]',
        'kinds': list([
          'api',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'DT',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'WARNING',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': 1,
            'status': 'WARNING',
            'total_num_checks': 1,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-09-09',
            'run_id': '198d2c64-664d-4b23-9c69-976247ac0c2d',
            'timestamp': 1757532027053.0,
          }),
          'materialization_status': 'DEGRADED',
        }),
      }),
      dict({
        'asset_key': 'RAW_DATA/users',
        'asset_key_parts': list([
          'RAW_DATA',
          'users',
        ]),
        'description': 'A table containing all users data',
        'group_name': 'RAW_DATA',
        'id': '["RAW_DATA", "users"]',
        'kinds': list([
          'api',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'created_at',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'WARNING',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': 2,
            'status': 'WARNING',
            'total_num_checks': 2,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-09-09',
            'run_id': '198d2c64-664d-4b23-9c69-976247ac0c2d',
            'timestamp': 1757532023589.0,
          }),
          'materialization_status': 'DEGRADED',
        }),
      }),
      dict({
        'asset_key': 'change_model',
        'asset_key_parts': list([
          'change_model',
        ]),
        'description': None,
        'group_name': 'default',
        'id': '["change_model"]',
        'kinds': list([
          'Kubernetes',
          'S3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'b0b7679c-5180-4bc1-b7d7-27a12047f01f',
            'timestamp': 1748458042286.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'continent_stats',
        'asset_key_parts': list([
          'continent_stats',
        ]),
        'description': None,
        'group_name': 'default',
        'id': '["continent_stats"]',
        'kinds': list([
          'Kubernetes',
          'S3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'b0b7679c-5180-4bc1-b7d7-27a12047f01f',
            'timestamp': 1748458050165.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'country_stats',
        'asset_key_parts': list([
          'country_stats',
        ]),
        'description': None,
        'group_name': 'default',
        'id': '["country_stats"]',
        'kinds': list([
          'Kubernetes',
          'S3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'b0b7679c-5180-4bc1-b7d7-27a12047f01f',
            'timestamp': 1748458032786.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'databricks/economic_indicators',
        'asset_key_parts': list([
          'databricks',
          'economic_indicators',
        ]),
        'description': 'Ledger loaded ',
        'group_name': 'ingestion',
        'id': '["databricks", "economic_indicators"]',
        'kinds': list([
          'databricks',
        ]),
        'metadata_entries': list([
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '26c59dcc-3484-4165-b281-e5254632ed4d',
            'timestamp': 1757505646980.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'databricks/news_sentiment',
        'asset_key_parts': list([
          'databricks',
          'news_sentiment',
        ]),
        'description': 'Ledger loaded ',
        'group_name': 'ingestion',
        'id': '["databricks", "news_sentiment"]',
        'kinds': list([
          'databricks',
        ]),
        'metadata_entries': list([
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '26c59dcc-3484-4165-b281-e5254632ed4d',
            'timestamp': 1757505646902.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'databricks/revenue',
        'asset_key_parts': list([
          'databricks',
          'revenue',
        ]),
        'description': 'Ledger loaded ',
        'group_name': 'ingestion',
        'id': '["databricks", "revenue"]',
        'kinds': list([
          'databricks',
        ]),
        'metadata_entries': list([
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '26c59dcc-3484-4165-b281-e5254632ed4d',
            'timestamp': 1757505650247.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'databricks_asset',
        'asset_key_parts': list([
          'databricks_asset',
        ]),
        'description': None,
        'group_name': 'FORECASTING',
        'id': '["databricks_asset"]',
        'kinds': list([
          'databricks',
          'pyspark',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'NOT_APPLICABLE',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'NOT_APPLICABLE',
            'total_num_checks': None,
          }),
          'freshness_info': None,
          'freshness_status': 'NOT_APPLICABLE',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'd5a01d8f-696e-4b7f-b1b3-351152bcf99d',
            'timestamp': 1748458352433.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
    ]),
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_assets_status_view_with_cursor_json]
  dict({
    'cursor': None,
    'has_more': False,
    'items': list([
    ]),
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_assets_with_cursor_json]
  dict({
    'cursor': None,
    'has_more': False,
    'items': list([
    ]),
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_multiple_assets_json]
  dict({
    'cursor': '["dbt", "model", "salesforce_source", "stg_salesforce__account_tmp"]',
    'has_more': True,
    'items': list([
      dict({
        'asset_key': 'change_model',
        'asset_key_parts': list([
          'change_model',
        ]),
        'description': None,
        'group_name': 'default',
        'id': 'basics.__repository__.["change_model"]',
        'kinds': list([
          'Kubernetes',
          'S3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'continent_stats',
        'asset_key_parts': list([
          'continent_stats',
        ]),
        'description': None,
        'group_name': 'default',
        'id': 'basics.__repository__.["continent_stats"]',
        'kinds': list([
          'Kubernetes',
          'S3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'country_stats',
        'asset_key_parts': list([
          'country_stats',
        ]),
        'description': None,
        'group_name': 'default',
        'id': 'basics.__repository__.["country_stats"]',
        'kinds': list([
          'Kubernetes',
          'S3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/company_perf',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_perf',
        ]),
        'description': '''
          dbt model for: company_perf 
           
          	select
          	        company,
          	        sum(n_orders) as n_orders,
          	        sum(total_revenue) as total_revenue
          	from {{ ref("company_stats") }}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "company_perf"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_perf',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_perf',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/company_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_stats',
        ]),
        'description': '''
          dbt model for: company_stats 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        order_date,
          	        company,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "company_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/order_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'order_stats',
        ]),
        'description': '''
          dbt model for: order_stats 
           
          	select
          	        {{ date_trunc("day", "order_date") }} as order_date,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	{% if is_incremental() %}
          	WHERE {{ date_trunc("day", "order_date") }} >=  '{{ var('min_date') }}' AND {{ date_trunc("day", "order_date") }} <=  '{{ var('max_date') }}'
          	{% endif %}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "order_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.order_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.order_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/orders_augmented',
        'asset_key_parts': list([
          'ANALYTICS',
          'orders_augmented',
        ]),
        'description': '''
          dbt model for: orders_augmented 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        o.*,
          	        u.company,
          	        l.state,
          	        l.zip_code
          	from {{ ref("orders_cleaned") }} o 
          
          	left join {{ ref("users_cleaned") }} u
          	       on o.user_id = u.user_id
          
          	 left join {{ ref("locations_cleaned") }} l
          	        on o.user_id = l.user_id
          
          	{% if is_incremental() %}
          	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "orders_augmented"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/sku_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'sku_stats',
        ]),
        'description': '''
          dbt model for: sku_stats 
           
          	select
          	        order_date,
          	        sku,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "sku_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/weekly_order_summary',
        'asset_key_parts': list([
          'ANALYTICS',
          'weekly_order_summary',
        ]),
        'description': '''
          dbt model for: weekly_order_summary 
           
          	{{
          	        config(
          	                tags=["core_kpis"]
          	        )
          	}}
          
          	select
          	        order_date,
          	        n_orders as num_orders
          	from {{ ref("order_stats") }}
          	{% if is_incremental() %}
          	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "weekly_order_summary"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.weekly_order_summary',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.weekly_order_summary',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'CLEANED/locations_cleaned',
        'asset_key_parts': list([
          'CLEANED',
          'locations_cleaned',
        ]),
        'description': '''
          dbt model for: locations_cleaned 
           
          	with source as (
              
          	select *
          	from {{ source("raw_data", "locations") }}
          
          	),
           
          	source_renamed as (
          
          	    select l_user_id as user_id,
          	           l_street_address as street_address,
          	           l_state as state,
          	           l_country as country,
          	           l_zip_code as zip_code,
          	           _sling_loaded_at
          	    from source
          
          	)
          
          	select *
          	from source_renamed
        ''',
        'group_name': 'CLEANED',
        'id': 'data-eng-pipeline.__repository__.["CLEANED", "locations_cleaned"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.locations_cleaned',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.locations_cleaned',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'CLEANED/orders_cleaned',
        'asset_key_parts': list([
          'CLEANED',
          'orders_cleaned',
        ]),
        'description': '''
          dbt model for: orders_cleaned 
           
          	{{config(tags="my_test_tag")}}
          	select
          	        user_id,
          	        quantity,
          	        purchase_price,
          	        sku,
          	        dt,
          	        cast(dt as datetime) as order_date,
          	        quantity * purchase_price as order_total
          	from {{ source("raw_data", "orders") }}
          	{% if is_incremental() %}
          	WHERE dt >= '{{ var('min_date') }}' AND dt <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'CLEANED',
        'id': 'data-eng-pipeline.__repository__.["CLEANED", "orders_cleaned"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.orders_cleaned',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'dt',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.orders_cleaned',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'CLEANED/users_cleaned',
        'asset_key_parts': list([
          'CLEANED',
          'users_cleaned',
        ]),
        'description': '''
          dbt model for: users_cleaned 
           
          	select
          	        user_id,
          	        created_at,
          	        company
          	from {{ source("raw_data", "users") }}
          	where not is_test_user
        ''',
        'group_name': 'CLEANED',
        'id': 'data-eng-pipeline.__repository__.["CLEANED", "users_cleaned"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.users_cleaned',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'created_at',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.users_cleaned',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'FORECASTING/big_orders',
        'asset_key_parts': list([
          'FORECASTING',
          'big_orders',
        ]),
        'description': 'Days where predicted orders surpass our current carrying capacity',
        'group_name': 'FORECASTING',
        'id': 'data-eng-pipeline.__repository__.["FORECASTING", "big_orders"]',
        'kinds': list([
          'databricks',
          'pyspark',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'intValue': 50,
            'label': 'resource_constrained_at',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'FORECASTING/predicted_orders',
        'asset_key_parts': list([
          'FORECASTING',
          'predicted_orders',
        ]),
        'description': 'Predicted orders for the next 30 days based on the fit paramters',
        'group_name': 'FORECASTING',
        'id': 'data-eng-pipeline.__repository__.["FORECASTING", "predicted_orders"]',
        'kinds': list([
          'pandas',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'MARKETING/avg_orders',
        'asset_key_parts': list([
          'MARKETING',
          'avg_orders',
        ]),
        'description': 'Computes avg order KPI, must be updated regularly for exec dashboard',
        'group_name': 'MARKETING',
        'id': 'data-eng-pipeline.__repository__.["MARKETING", "avg_orders"]',
        'kinds': list([
          'pandas',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'MARKETING/key_product_deepdive',
        'asset_key_parts': list([
          'MARKETING',
          'key_product_deepdive',
        ]),
        'description': 'Creates a file for a BI tool based on the current quarters top product, represented as a dynamic partition',
        'group_name': 'MARKETING',
        'id': 'data-eng-pipeline.__repository__.["MARKETING", "key_product_deepdive"]',
        'kinds': list([
          'pandas',
          's3',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'MARKETING/min_order',
        'asset_key_parts': list([
          'MARKETING',
          'min_order',
        ]),
        'description': 'Computes min order KPI',
        'group_name': 'MARKETING',
        'id': 'data-eng-pipeline.__repository__.["MARKETING", "min_order"]',
        'kinds': list([
          'pandas',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'RAW_DATA/orders',
        'asset_key_parts': list([
          'RAW_DATA',
          'orders',
        ]),
        'description': 'A table containing all orders that have been placed',
        'group_name': 'RAW_DATA',
        'id': 'data-eng-pipeline.__repository__.["RAW_DATA", "orders"]',
        'kinds': list([
          'api',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'DT',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'RAW_DATA/users',
        'asset_key_parts': list([
          'RAW_DATA',
          'users',
        ]),
        'description': 'A table containing all users data',
        'group_name': 'RAW_DATA',
        'id': 'data-eng-pipeline.__repository__.["RAW_DATA", "users"]',
        'kinds': list([
          'api',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'created_at',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'databricks_asset',
        'asset_key_parts': list([
          'databricks_asset',
        ]),
        'description': None,
        'group_name': 'FORECASTING',
        'id': 'data-eng-pipeline.__repository__.["databricks_asset"]',
        'kinds': list([
          'databricks',
          'pyspark',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'databricks/economic_indicators',
        'asset_key_parts': list([
          'databricks',
          'economic_indicators',
        ]),
        'description': 'Ledger loaded ',
        'group_name': 'ingestion',
        'id': 'hooli_airlift.__repository__.["databricks", "economic_indicators"]',
        'kinds': list([
          'databricks',
        ]),
        'metadata_entries': list([
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'databricks/news_sentiment',
        'asset_key_parts': list([
          'databricks',
          'news_sentiment',
        ]),
        'description': 'Ledger loaded ',
        'group_name': 'ingestion',
        'id': 'hooli_airlift.__repository__.["databricks", "news_sentiment"]',
        'kinds': list([
          'databricks',
        ]),
        'metadata_entries': list([
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'databricks/revenue',
        'asset_key_parts': list([
          'databricks',
          'revenue',
        ]),
        'description': 'Ledger loaded ',
        'group_name': 'ingestion',
        'id': 'hooli_airlift.__repository__.["databricks", "revenue"]',
        'kinds': list([
          'databricks',
        ]),
        'metadata_entries': list([
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'RAW_DATA/locations',
        'asset_key_parts': list([
          'RAW_DATA',
          'locations',
        ]),
        'description': None,
        'group_name': 'RAW_DATA',
        'id': 'hooli_data_ingest.__repository__.["RAW_DATA", "locations"]',
        'kinds': list([
          'SNOWFLAKE',
          'sling',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'jsonString': '{"object": "locations"}',
            'label': 'stream_config',
          }),
          dict({
            'description': None,
            'label': 'dagster_sling/dagster_sling_translator',
            'text': '[CustomSlingTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'jsonString': '{"defaults": {"mode": "full-refresh", "object": "{stream_file_folder}.{stream_file_name}", "source_options": {"format": "csv"}}, "source": "S3", "streams": {"s3://hooli-demo/embedded-elt/locations.csv": {"object": "locations"}}, "target": "SNOWFLAKE_PROD"}',
            'label': 'dagster_sling/sling_replication_config',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
    ]),
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_nested_asset_json]
  dict({
    'asset_key': 'forecasting/model_stats_by_month',
    'asset_key_parts': list([
      'forecasting',
      'model_stats_by_month',
    ]),
    'description': 'Model errors by month',
    'group_name': 'FORECASTING',
    'id': 'data-eng-pipeline.__repository__.["forecasting", "model_stats_by_month"]',
    'kinds': list([
      'scikitlearn',
      'snowflake',
    ]),
    'metadata_entries': list([
      dict({
        'description': None,
        'label': 'dagster/code_references',
      }),
    ]),
    'status': None,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_paginated_assets_json]
  dict({
    'cursor': '["ANALYTICS", "users_cleaned"]',
    'has_more': True,
    'items': list([
      dict({
        'asset_key': 'ANALYTICS/company_perf',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_perf',
        ]),
        'description': '''
          dbt model for: company_perf 
           
          	select
          	        company,
          	        sum(n_orders) as n_orders,
          	        sum(total_revenue) as total_revenue
          	from {{ ref("company_stats") }}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "company_perf"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_perf',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_perf',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/company_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_stats',
        ]),
        'description': '''
          dbt model for: company_stats 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        order_date,
          	        company,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "company_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/order_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'order_stats',
        ]),
        'description': '''
          dbt model for: order_stats 
           
          	select
          	        {{ date_trunc("day", "order_date") }} as order_date,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	{% if is_incremental() %}
          	WHERE {{ date_trunc("day", "order_date") }} >=  '{{ var('min_date') }}' AND {{ date_trunc("day", "order_date") }} <=  '{{ var('max_date') }}'
          	{% endif %}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "order_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.order_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.order_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/orders_augmented',
        'asset_key_parts': list([
          'ANALYTICS',
          'orders_augmented',
        ]),
        'description': '''
          dbt model for: orders_augmented 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        o.*,
          	        u.company,
          	        l.state,
          	        l.zip_code
          	from {{ ref("orders_cleaned") }} o 
          
          	left join {{ ref("users_cleaned") }} u
          	       on o.user_id = u.user_id
          
          	 left join {{ ref("locations_cleaned") }} l
          	        on o.user_id = l.user_id
          
          	{% if is_incremental() %}
          	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "orders_augmented"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
      dict({
        'asset_key': 'ANALYTICS/sku_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'sku_stats',
        ]),
        'description': '''
          dbt model for: sku_stats 
           
          	select
          	        order_date,
          	        sku,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': 'data-eng-pipeline.__repository__.["ANALYTICS", "sku_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': None,
      }),
    ]),
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_paginated_assets_status_view_json]
  dict({
    'cursor': '["ANALYTICS", "users_cleaned"]',
    'has_more': True,
    'items': list([
      dict({
        'asset_key': 'ANALYTICS/company_perf',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_perf',
        ]),
        'description': '''
          dbt model for: company_perf 
           
          	select
          	        company,
          	        sum(n_orders) as n_orders,
          	        sum(total_revenue) as total_revenue
          	from {{ ref("company_stats") }}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "company_perf"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_perf',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_perf',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '83112ac7-a739-4b79-8f1f-6d91911a029a',
            'timestamp': 1757376145523.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/company_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'company_stats',
        ]),
        'description': '''
          dbt model for: company_stats 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        order_date,
          	        company,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "company_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.company_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.company_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'HEALTHY',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'HEALTHY',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': 'a484f830-3007-424b-862e-4fefbd733bab',
            'timestamp': 1757521279949.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/order_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'order_stats',
        ]),
        'description': '''
          dbt model for: order_stats 
           
          	select
          	        {{ date_trunc("day", "order_date") }} as order_date,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	{% if is_incremental() %}
          	WHERE {{ date_trunc("day", "order_date") }} >=  '{{ var('min_date') }}' AND {{ date_trunc("day", "order_date") }} <=  '{{ var('max_date') }}'
          	{% endif %}
          	group by 1
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "order_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.order_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.order_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'WARNING',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'WARNING',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-08-31',
            'run_id': '112a4461-789e-477b-a88c-872cf8c24316',
            'timestamp': 1757203402552.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/orders_augmented',
        'asset_key_parts': list([
          'ANALYTICS',
          'orders_augmented',
        ]),
        'description': '''
          dbt model for: orders_augmented 
           
          	{{
          	        config(tags=["core_kpis"])
          	}}
          	select
          	        o.*,
          	        u.company,
          	        l.state,
          	        l.zip_code
          	from {{ ref("orders_cleaned") }} o 
          
          	left join {{ ref("users_cleaned") }} u
          	       on o.user_id = u.user_id
          
          	 left join {{ ref("locations_cleaned") }} l
          	        on o.user_id = l.user_id
          
          	{% if is_incremental() %}
          	WHERE o.order_date >= '{{ var('min_date') }}' AND o.order_date <= '{{ var('max_date') }}'
          	{% endif %}
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "orders_augmented"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/column_schema',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.orders_augmented',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'HEALTHY',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': None,
            'status': 'HEALTHY',
            'total_num_checks': None,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'WARNING',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': '2025-09-09',
            'run_id': '085aa81e-11f7-4848-8e25-8b9e37b3a753',
            'timestamp': 1757462531632.0,
          }),
          'materialization_status': 'DEGRADED',
        }),
      }),
      dict({
        'asset_key': 'ANALYTICS/sku_stats',
        'asset_key_parts': list([
          'ANALYTICS',
          'sku_stats',
        ]),
        'description': '''
          dbt model for: sku_stats 
           
          	select
          	        order_date,
          	        sku,
          	        count(*) as n_orders,
          	        sum(order_total) as total_revenue
          	from {{ ref("orders_augmented") }}
          	group by 1, 2
        ''',
        'group_name': 'ANALYTICS',
        'id': '["ANALYTICS", "sku_stats"]',
        'kinds': list([
          'dbt',
          'snowflake',
        ]),
        'metadata_entries': list([
          dict({
            'description': None,
            'label': 'dagster-dbt/materialization_type',
            'text': 'table',
          }),
          dict({
            'description': None,
            'label': 'dagster/table_name',
            'text': 'DEMO_DB2.analytics.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'partition_expr',
            'text': 'order_date',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/manifest',
            'text': '[DbtManifestWrapper] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/dagster_dbt_translator',
            'text': '[CustomDagsterDbtTranslator] (unserializable)',
          }),
          dict({
            'description': None,
            'label': 'dagster_dbt/unique_id',
            'text': 'model.dbt_project.sku_stats',
          }),
          dict({
            'description': None,
            'label': 'dagster/code_references',
          }),
        ]),
        'status': dict({
          'asset_checks_status': 'WARNING',
          'asset_health': 'DEGRADED',
          'checks_status': dict({
            'num_failed_checks': None,
            'num_warning_checks': 1,
            'status': 'WARNING',
            'total_num_checks': 1,
          }),
          'freshness_info': dict({
            'cron_schedule': None,
            'current_lag_minutes': None,
            'current_minutes_late': None,
            'latest_materialization_minutes_late': None,
            'maximum_lag_minutes': None,
          }),
          'freshness_status': 'DEGRADED',
          'health_metadata': None,
          'latest_materialization': dict({
            'partition': None,
            'run_id': '41b0e33d-a965-423f-acca-b444a7058dba',
            'timestamp': 1756685035863.0,
          }),
          'materialization_status': 'HEALTHY',
        }),
      }),
    ]),
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_single_asset_json]
  dict({
    'asset_key': 'country_stats',
    'asset_key_parts': list([
      'country_stats',
    ]),
    'description': None,
    'group_name': 'default',
    'id': 'basics.__repository__.["country_stats"]',
    'kinds': list([
      'Kubernetes',
      'S3',
    ]),
    'metadata_entries': list([
      dict({
        'description': None,
        'label': 'dagster/code_references',
      }),
    ]),
    'status': None,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_single_asset_status_view_human_readable_text]
  '''
  Asset Key: forecasting/model_stats_by_month
  ID: ["forecasting", "model_stats_by_month"]
  Description: Model errors by month
  Group: FORECASTING
  Kinds: scikitlearn, snowflake
  
  Status Information:
    Asset Health: HEALTHY
    Materialization Status: HEALTHY
    Freshness Status: NOT_APPLICABLE
    Asset Checks Status: NOT_APPLICABLE
    Latest Materialization: 2023-02-28 22:02:57
    Latest Run ID: fc70230e-2fcc-4bff-8400-5eefca046bbf
    Latest Partition: 2023-01-01
  
  Metadata:
    dagster/code_references: None
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[asset_success_single_asset_status_view_json]
  dict({
    'asset_key': 'forecasting/model_stats_by_month',
    'asset_key_parts': list([
      'forecasting',
      'model_stats_by_month',
    ]),
    'description': 'Model errors by month',
    'group_name': 'FORECASTING',
    'id': '["forecasting", "model_stats_by_month"]',
    'kinds': list([
      'scikitlearn',
      'snowflake',
    ]),
    'metadata_entries': list([
      dict({
        'description': None,
        'label': 'dagster/code_references',
      }),
    ]),
    'status': dict({
      'asset_checks_status': 'NOT_APPLICABLE',
      'asset_health': 'HEALTHY',
      'checks_status': dict({
        'num_failed_checks': None,
        'num_warning_checks': None,
        'status': 'NOT_APPLICABLE',
        'total_num_checks': None,
      }),
      'freshness_info': None,
      'freshness_status': 'NOT_APPLICABLE',
      'health_metadata': None,
      'latest_materialization': dict({
        'partition': '2023-01-01',
        'run_id': 'fc70230e-2fcc-4bff-8400-5eefca046bbf',
        'timestamp': 1677621777152.0,
      }),
      'materialization_status': 'HEALTHY',
    }),
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[deployment_empty_deployments_json]
  dict({
    'items': list([
      dict({
        'id': 87,
        'name': 'data-eng-prod',
        'type': 'PRODUCTION',
      }),
      dict({
        'id': 190248,
        'name': 'gtm20',
        'type': 'PRODUCTION',
      }),
      dict({
        'id': 213933,
        'name': 'data-eng-staging',
        'type': 'PRODUCTION',
      }),
      dict({
        'id': 217021,
        'name': 'data-eng-dev',
        'type': 'PRODUCTION',
      }),
    ]),
    'total': 4,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[deployment_success_multiple_deployments_json]
  dict({
    'items': list([
      dict({
        'id': 87,
        'name': 'data-eng-prod',
        'type': 'PRODUCTION',
      }),
      dict({
        'id': 190248,
        'name': 'gtm20',
        'type': 'PRODUCTION',
      }),
      dict({
        'id': 213933,
        'name': 'data-eng-staging',
        'type': 'PRODUCTION',
      }),
      dict({
        'id': 217021,
        'name': 'data-eng-dev',
        'type': 'PRODUCTION',
      }),
    ]),
    'total': 4,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[deployment_success_multiple_deployments_text_text]
  '''
  Name: data-eng-prod
  ID: 87
  Type: PRODUCTION
  
  Name: gtm20
  ID: 190248
  Type: PRODUCTION
  
  Name: data-eng-staging
  ID: 213933
  Type: PRODUCTION
  
  Name: data-eng-dev
  ID: 217021
  Type: PRODUCTION
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_cursor_no_recording_json_json]
  '''
  {"error": "Exhausted 0 responses"}
  Error: Failed to get logs for run 85156191-170d-4229-8eba-14450b6ca9e3: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_cursor_no_recording_text_text]
  '''
  Error querying Dagster Plus API: Exhausted 0 responses
  Error: Failed to get logs for run 85156191-170d-4229-8eba-14450b6ca9e3: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_empty_logs_no_recording_json_json]
  '''
  {"error": "Exhausted 0 responses"}
  Error: Failed to get logs for run empty-run-uuid-0000-0000-000000000000: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_empty_logs_no_recording_text_text]
  '''
  Error querying Dagster Plus API: Exhausted 0 responses
  Error: Failed to get logs for run empty-run-uuid-0000-0000-000000000000: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_empty_run_id_json_json]
  '''
  {"error": "Exhausted 0 responses"}
  Error: Failed to get logs for run '': Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_empty_run_id_text_text]
  '''
  Error querying Dagster Plus API: Exhausted 0 responses
  Error: Failed to get logs for run '': Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_invalid_level_json_json]
  dict({
    'count': 0,
    'cursor': 'eyJ0eXBlIjogIlNUT1JBR0VfSUQiLCAidmFsdWUiOiA0ODgwODU1MzE0M30=',
    'hasMore': False,
    'logs': list([
    ]),
    'run_id': '85156191-170d-4229-8eba-14450b6ca9e3',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_invalid_level_text_text]
  '''
  No logs found for run 85156191-170d-4229-8eba-14450b6ca9e3
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_malformed_run_id_json_json]
  '''
  {"error": "Exhausted 0 responses"}
  Error: Failed to get logs for run invalid-uuid-format: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_malformed_run_id_text_text]
  '''
  Error querying Dagster Plus API: Exhausted 0 responses
  Error: Failed to get logs for run invalid-uuid-format: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_run_not_found_json_json]
  '''
  {"error": "Exhausted 0 responses"}
  Error: Failed to get logs for run nonexistent-run-uuid-1234-5678-900000000000: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_error_run_not_found_text_text]
  '''
  Error querying Dagster Plus API: Exhausted 0 responses
  Error: Failed to get logs for run nonexistent-run-uuid-1234-5678-900000000000: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_basic_json_json]
  dict({
    'count': 20,
    'cursor': 'eyJ0eXBlIjogIlNUT1JBR0VfSUQiLCAidmFsdWUiOiA0ODgyMTg1Nzg2MH0=',
    'hasMore': True,
    'logs': list([
      dict({
        'error': None,
        'eventType': 'ASSET_CHECK_EVALUATION_PLANNED',
        'level': 'DEBUG',
        'message': 'check_avg_orders_freshness_job intends to execute asset check anomaly_detection_freshness_check on asset ["MARKETING", "avg_orders"]',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817801771',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_ENQUEUED',
        'level': 'INFO',
        'message': '',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817801798',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_STARTING',
        'level': 'INFO',
        'message': '',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817804629',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Sending a request to the agent to execute steps in the user cloud',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817804660',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': '[DagsterCloudAgent] Agent d0a5374c is launching run b45fff8a-7def-43b8-805d-1cf5f435c997',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817804845',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': '[CloudK8sRunLauncher] Creating Kubernetes run worker job',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817804996',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': '[CloudK8sRunLauncher] Kubernetes run worker job created',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817805113',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Starting run metrics thread with container_metrics_enabled=True and python_metrics_enabled=False',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817813386',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Started process for run (pid: 1).',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817813451',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_START',
        'level': 'DEBUG',
        'message': 'Started execution of run for "check_avg_orders_freshness_job".',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817827876',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'DEBUG',
        'message': 'Executing steps using multiprocess executor: parent process (pid: 1)',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817827919',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTING',
        'level': 'DEBUG',
        'message': 'Launching subprocess for "anomaly_detection_freshness_check_458e9b8f".',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817828047',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTED',
        'level': 'DEBUG',
        'message': 'Executing step "anomaly_detection_freshness_check_458e9b8f" in subprocess.',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817829513',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_STARTED',
        'level': 'DEBUG',
        'message': 'Starting initialization of resources [io_manager].',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817833373',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_SUCCESS',
        'level': 'DEBUG',
        'message': 'Finished initialization of resources [io_manager].',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817833453',
      }),
      dict({
        'error': None,
        'eventType': 'LOGS_CAPTURED',
        'level': 'DEBUG',
        'message': 'Started capturing logs in process (pid: 19).',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': None,
        'timestamp': '1758817833507',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_START',
        'level': 'DEBUG',
        'message': 'Started execution of step "anomaly_detection_freshness_check_458e9b8f".',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817833533',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_OUTPUT',
        'level': 'DEBUG',
        'message': 'Yielded output "MARKETING__avg_orders_anomaly_detection_freshness_check" of type "Any". (Type check passed).',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817833714',
      }),
      dict({
        'error': None,
        'eventType': 'ASSET_CHECK_EVALUATION',
        'level': 'DEBUG',
        'message': "Asset check 'anomaly_detection_freshness_check' on 'MARKETING/avg_orders' did not pass. Description: 'Asset is overdue for an update. The last update was 2 days, 16 hours, 25 minutes, 24 seconds ago, which is past the allowed distance of 2 days, 5 minutes, 11 seconds ago.'",
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817833766',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_SUCCESS',
        'level': 'DEBUG',
        'message': 'Finished execution of step "anomaly_detection_freshness_check_458e9b8f" in 246ms.',
        'runId': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
        'stepKey': 'anomaly_detection_freshness_check_458e9b8f',
        'timestamp': '1758817833807',
      }),
    ]),
    'run_id': 'b45fff8a-7def-43b8-805d-1cf5f435c997',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_basic_text_text]
  '''
  Logs for run b45fff8a-7def-43b8-805d-1cf5f435c997:
  
  TIMESTAMP            LEVEL    STEP_KEY                  MESSAGE
  --------------------------------------------------------------------------------
  2025-09-25 16:30:01  DEBUG    anomaly_detection_freshn  check_avg_orders_freshness_job intends to execute asset check anomaly_detection_freshness_check on asset ["MARKETING", "avg_orders"]
  2025-09-25 16:30:01  INFO                               
  2025-09-25 16:30:04  INFO                               
  2025-09-25 16:30:04  INFO                               Sending a request to the agent to execute steps in the user cloud
  2025-09-25 16:30:04  INFO                               [DagsterCloudAgent] Agent d0a5374c is launching run b45fff8a-7def-43b8-805d-1cf5f435c997
  2025-09-25 16:30:04  INFO                               [CloudK8sRunLauncher] Creating Kubernetes run worker job
  2025-09-25 16:30:05  INFO                               [CloudK8sRunLauncher] Kubernetes run worker job created
  2025-09-25 16:30:13  INFO                               Starting run metrics thread with container_metrics_enabled=True and python_metrics_enabled=False
  2025-09-25 16:30:13  INFO                               Started process for run (pid: 1).
  2025-09-25 16:30:27  DEBUG                              Started execution of run for "check_avg_orders_freshness_job".
  2025-09-25 16:30:27  DEBUG                              Executing steps using multiprocess executor: parent process (pid: 1)
  2025-09-25 16:30:28  DEBUG    anomaly_detection_freshn  Launching subprocess for "anomaly_detection_freshness_check_458e9b8f".
  2025-09-25 16:30:29  DEBUG    anomaly_detection_freshn  Executing step "anomaly_detection_freshness_check_458e9b8f" in subprocess.
  2025-09-25 16:30:33  DEBUG    anomaly_detection_freshn  Starting initialization of resources [io_manager].
  2025-09-25 16:30:33  DEBUG    anomaly_detection_freshn  Finished initialization of resources [io_manager].
  2025-09-25 16:30:33  DEBUG                              Started capturing logs in process (pid: 19).
  2025-09-25 16:30:33  DEBUG    anomaly_detection_freshn  Started execution of step "anomaly_detection_freshness_check_458e9b8f".
  2025-09-25 16:30:33  DEBUG    anomaly_detection_freshn  Yielded output "MARKETING__avg_orders_anomaly_detection_freshness_check" of type "Any". (Type check passed).
  2025-09-25 16:30:33  DEBUG    anomaly_detection_freshn  Asset check 'anomaly_detection_freshness_check' on 'MARKETING/avg_orders' did not pass. Description: 'Asset is overdue for an update. The last update was 2 days, 16 hours, 25 minutes, 24 seconds ago, which is past the allowed distance of 2 days, 5 minutes, 11 seconds ago.'
  2025-09-25 16:30:33  DEBUG    anomaly_detection_freshn  Finished execution of step "anomaly_detection_freshness_check_458e9b8f" in 246ms.
  
  Total log entries: 20
  Note: More logs available (use --limit to increase or --cursor to paginate)
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_debug_level_json_json]
  dict({
    'count': 0,
    'cursor': 'eyJ0eXBlIjogIlNUT1JBR0VfSUQiLCAidmFsdWUiOiA0ODgwODUzNTQzOH0=',
    'hasMore': True,
    'logs': list([
    ]),
    'run_id': '85156191-170d-4229-8eba-14450b6ca9e3',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_debug_level_text_text]
  '''
  No logs found for run 85156191-170d-4229-8eba-14450b6ca9e3
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_empty_json_json]
  '''
  {"error": "Exhausted 0 responses"}
  Error: Failed to get logs for run empty-run-uuid-0000-0000-000000000000: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_empty_text_text]
  '''
  Error querying Dagster Plus API: Exhausted 0 responses
  Error: Failed to get logs for run empty-run-uuid-0000-0000-000000000000: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_error_level_only_json_json]
  dict({
    'count': 0,
    'cursor': 'eyJ0eXBlIjogIlNUT1JBR0VfSUQiLCAidmFsdWUiOiA0ODgwODU1MzE0M30=',
    'hasMore': False,
    'logs': list([
    ]),
    'run_id': '85156191-170d-4229-8eba-14450b6ca9e3',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_error_level_only_text_text]
  '''
  No logs found for run 85156191-170d-4229-8eba-14450b6ca9e3
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_small_limit_json_json]
  dict({
    'count': 5,
    'cursor': 'eyJ0eXBlIjogIlNUT1JBR0VfSUQiLCAidmFsdWUiOiA0ODgwODUyODM1MX0=',
    'hasMore': True,
    'logs': list([
      dict({
        'error': None,
        'eventType': 'ASSET_MATERIALIZATION_PLANNED',
        'level': 'DEBUG',
        'message': 'run_etl_pipeline intends to materialize asset ["enriched_data"]',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.concat_chunk_list',
        'timestamp': '1758808865047',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Launched as an automatic retry',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808865075',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_ENQUEUED',
        'level': 'INFO',
        'message': '',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808865098',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_STARTING',
        'level': 'INFO',
        'message': '',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808867161',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Sending a request to the agent to execute steps in the user cloud',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808867189',
      }),
    ]),
    'run_id': '85156191-170d-4229-8eba-14450b6ca9e3',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_small_limit_text_text]
  '''
  Logs for run 85156191-170d-4229-8eba-14450b6ca9e3:
  
  TIMESTAMP            LEVEL    STEP_KEY                  MESSAGE
  --------------------------------------------------------------------------------
  2025-09-25 14:01:05  DEBUG    enriched_data.concat_chu  run_etl_pipeline intends to materialize asset ["enriched_data"]
  2025-09-25 14:01:05  INFO                               Launched as an automatic retry
  2025-09-25 14:01:05  INFO                               
  2025-09-25 14:01:07  INFO                               
  2025-09-25 14:01:07  INFO                               Sending a request to the agent to execute steps in the user cloud
  
  Total log entries: 5
  Note: More logs available (use --limit to increase or --cursor to paginate)
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_step_filter_json_json]
  dict({
    'count': 3,
    'cursor': 'eyJ0eXBlIjogIlNUT1JBR0VfSUQiLCAidmFsdWUiOiA0ODgwODU0MDMyNn0=',
    'hasMore': True,
    'logs': list([
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTING',
        'level': 'DEBUG',
        'message': 'Launching subprocess for "enriched_data.process_chunk[11]".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808871633',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTED',
        'level': 'DEBUG',
        'message': 'Executing step "enriched_data.process_chunk[11]" in subprocess.',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808872870',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_STARTED',
        'level': 'DEBUG',
        'message': 'Starting initialization of resources [api, io_manager].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808873361',
      }),
    ]),
    'run_id': '85156191-170d-4229-8eba-14450b6ca9e3',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_step_filter_text_text]
  '''
  Logs for run 85156191-170d-4229-8eba-14450b6ca9e3:
  
  TIMESTAMP            LEVEL    STEP_KEY                  MESSAGE
  --------------------------------------------------------------------------------
  2025-09-25 14:01:11  DEBUG    enriched_data.process_ch  Launching subprocess for "enriched_data.process_chunk[11]".
  2025-09-25 14:01:12  DEBUG    enriched_data.process_ch  Executing step "enriched_data.process_chunk[11]" in subprocess.
  2025-09-25 14:01:13  DEBUG    enriched_data.process_ch  Starting initialization of resources [api, io_manager].
  
  Total log entries: 3
  Note: More logs available (use --limit to increase or --cursor to paginate)
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_with_cursor_json_json]
  '''
  {"error": "Exhausted 0 responses"}
  Error: Failed to get logs for run 85156191-170d-4229-8eba-14450b6ca9e3: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_with_cursor_text_text]
  '''
  Error querying Dagster Plus API: Exhausted 0 responses
  Error: Failed to get logs for run 85156191-170d-4229-8eba-14450b6ca9e3: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_with_errors_json_json]
  dict({
    'count': 41,
    'cursor': 'eyJ0eXBlIjogIlNUT1JBR0VfSUQiLCAidmFsdWUiOiA0ODgwODU1MzE0M30=',
    'hasMore': False,
    'logs': list([
      dict({
        'error': None,
        'eventType': 'ASSET_MATERIALIZATION_PLANNED',
        'level': 'DEBUG',
        'message': 'run_etl_pipeline intends to materialize asset ["enriched_data"]',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.concat_chunk_list',
        'timestamp': '1758808865047',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Launched as an automatic retry',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808865075',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_ENQUEUED',
        'level': 'INFO',
        'message': '',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808865098',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_STARTING',
        'level': 'INFO',
        'message': '',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808867161',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Sending a request to the agent to execute steps in the user cloud',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808867189',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': '[DagsterCloudAgent] Agent 3a659214 is launching run 85156191-170d-4229-8eba-14450b6ca9e3',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808867555',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': '[CloudK8sRunLauncher] Creating Kubernetes run worker job',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808867738',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': '[CloudK8sRunLauncher] Kubernetes run worker job created',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808867910',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Starting run metrics thread with container_metrics_enabled=True and python_metrics_enabled=False',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808870636',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Started process for run (pid: 1).',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808870686',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_START',
        'level': 'DEBUG',
        'message': 'Started execution of run for "run_etl_pipeline".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808871488',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'DEBUG',
        'message': 'Executing steps using multiprocess executor: parent process (pid: 1)',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808871524',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTING',
        'level': 'DEBUG',
        'message': 'Launching subprocess for "enriched_data.process_chunk[11]".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808871633',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTED',
        'level': 'DEBUG',
        'message': 'Executing step "enriched_data.process_chunk[11]" in subprocess.',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808872870',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_STARTED',
        'level': 'DEBUG',
        'message': 'Starting initialization of resources [api, io_manager].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808873361',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_SUCCESS',
        'level': 'DEBUG',
        'message': 'Finished initialization of resources [api, io_manager].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808873521',
      }),
      dict({
        'error': None,
        'eventType': 'LOGS_CAPTURED',
        'level': 'DEBUG',
        'message': 'Started capturing logs in process (pid: 16).',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808873570',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_START',
        'level': 'DEBUG',
        'message': 'Started execution of step "enriched_data.process_chunk[11]".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808873607',
      }),
      dict({
        'error': None,
        'eventType': None,
        'level': 'DEBUG',
        'message': 'Loading file from: /opt/dagster/dagster_home/storage/385defa2-7ac6-4d18-8a88-585a42393d9c/enriched_data.split_rows/result/11 using PickledObjectFilesystemIOManager...',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808873644',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_UP_FOR_RETRY',
        'level': 'DEBUG',
        'message': 'Execution of step "enriched_data.process_chunk[11]" failed and has requested a retry.',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808873697',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTING',
        'level': 'DEBUG',
        'message': 'Launching subprocess for "enriched_data.process_chunk[11]".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808873742',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTED',
        'level': 'DEBUG',
        'message': 'Executing step "enriched_data.process_chunk[11]" in subprocess.',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808874924',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_STARTED',
        'level': 'DEBUG',
        'message': 'Starting initialization of resources [api, io_manager].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808875309',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_SUCCESS',
        'level': 'DEBUG',
        'message': 'Finished initialization of resources [api, io_manager].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808875444',
      }),
      dict({
        'error': None,
        'eventType': 'LOGS_CAPTURED',
        'level': 'DEBUG',
        'message': 'Started capturing logs in process (pid: 26).',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808875526',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_RESTARTED',
        'level': 'DEBUG',
        'message': 'Started re-execution (attempt # 2) of step "enriched_data.process_chunk[11]".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808875655',
      }),
      dict({
        'error': None,
        'eventType': None,
        'level': 'DEBUG',
        'message': 'Loading file from: /opt/dagster/dagster_home/storage/385defa2-7ac6-4d18-8a88-585a42393d9c/enriched_data.split_rows/result/11 using PickledObjectFilesystemIOManager...',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808875737',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_UP_FOR_RETRY',
        'level': 'DEBUG',
        'message': 'Execution of step "enriched_data.process_chunk[11]" failed and has requested a retry.',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808875801',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTING',
        'level': 'DEBUG',
        'message': 'Launching subprocess for "enriched_data.process_chunk[11]".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808875835',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_WORKER_STARTED',
        'level': 'DEBUG',
        'message': 'Executing step "enriched_data.process_chunk[11]" in subprocess.',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808876893',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_STARTED',
        'level': 'DEBUG',
        'message': 'Starting initialization of resources [api, io_manager].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808877224',
      }),
      dict({
        'error': None,
        'eventType': 'RESOURCE_INIT_SUCCESS',
        'level': 'DEBUG',
        'message': 'Finished initialization of resources [api, io_manager].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808877380',
      }),
      dict({
        'error': None,
        'eventType': 'LOGS_CAPTURED',
        'level': 'DEBUG',
        'message': 'Started capturing logs in process (pid: 36).',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808877439',
      }),
      dict({
        'error': None,
        'eventType': 'STEP_RESTARTED',
        'level': 'DEBUG',
        'message': 'Started re-execution (attempt # 3) of step "enriched_data.process_chunk[11]".',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808877601',
      }),
      dict({
        'error': None,
        'eventType': None,
        'level': 'DEBUG',
        'message': 'Loading file from: /opt/dagster/dagster_home/storage/385defa2-7ac6-4d18-8a88-585a42393d9c/enriched_data.split_rows/result/11 using PickledObjectFilesystemIOManager...',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808877680',
      }),
      dict({
        'error': dict({
          'cause': dict({
            'cause': None,
            'className': 'FileNotFoundError',
            'message': '''
              FileNotFoundError: [Errno 2] No such file or directory: '/opt/dagster/dagster_home/storage/385defa2-7ac6-4d18-8a88-585a42393d9c/enriched_data.split_rows/result/11'
  
            ''',
            'stack': list([
              '''
                  File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 57, in op_execution_error_boundary
                    yield
  
              ''',
              '''
                  File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 619, in _load_input_with_input_manager
                    value = input_manager.load_input(context)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
              ''',
              '''
                  File "/usr/local/lib/python3.12/site-packages/dagster/_core/storage/upath_io_manager.py", line 406, in load_input
                    return self._load_single_input(path, context)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
              ''',
              '''
                  File "/usr/local/lib/python3.12/site-packages/dagster/_core/storage/upath_io_manager.py", line 273, in _load_single_input
                    obj = self.load_from_path(context=context, path=path)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
              ''',
              '''
                  File "/usr/local/lib/python3.12/site-packages/dagster/_core/storage/fs_io_manager.py", line 284, in load_from_path
                    with path.open("rb") as file:
                         ^^^^^^^^^^^^^^^
  
              ''',
              '''
                  File "/usr/local/lib/python3.12/site-packages/upath/implementations/local.py", line 134, in open
                    return PosixPath.open(self, mode, buffering, encoding, errors, newline)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
              ''',
              '''
                  File "/usr/local/lib/python3.12/pathlib.py", line 1013, in open
                    return io.open(self, mode, buffering, encoding, errors, newline)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
              ''',
            ]),
            'stackTrace': '''
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 57, in op_execution_error_boundary
                  yield
              
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 619, in _load_input_with_input_manager
                  value = input_manager.load_input(context)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
              
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/storage/upath_io_manager.py", line 406, in load_input
                  return self._load_single_input(path, context)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
              
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/storage/upath_io_manager.py", line 273, in _load_single_input
                  obj = self.load_from_path(context=context, path=path)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
              
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/storage/fs_io_manager.py", line 284, in load_from_path
                  with path.open("rb") as file:
                       ^^^^^^^^^^^^^^^
              
                File "/usr/local/lib/python3.12/site-packages/upath/implementations/local.py", line 134, in open
                  return PosixPath.open(self, mode, buffering, encoding, errors, newline)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
              
                File "/usr/local/lib/python3.12/pathlib.py", line 1013, in open
                  return io.open(self, mode, buffering, encoding, errors, newline)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
            ''',
          }),
          'className': 'RetryRequestedFromPolicy',
          'message': '''
            Exceeded max_retries of 2
  
          ''',
          'stack': list([
            '''
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_plan.py", line 246, in dagster_event_sequence_for_step
                  yield from check.generator(step_events)
  
            ''',
            '''
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_step.py", line 468, in core_dagster_event_sequence_for_step
                  for event_or_input_value in step_input.source.load_input_object(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
            ''',
            '''
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 364, in load_input_object
                  yield from _load_input_with_input_manager(input_manager, load_input_context)
  
            ''',
            '''
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 612, in _load_input_with_input_manager
                  with op_execution_error_boundary(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
            ''',
            '''
                File "/usr/local/lib/python3.12/contextlib.py", line 158, in __exit__
                  self.gen.throw(value)
  
            ''',
            '''
                File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 75, in op_execution_error_boundary
                  raise RetryRequestedFromPolicy(
  
            ''',
          ]),
          'stackTrace': '''
              File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_plan.py", line 246, in dagster_event_sequence_for_step
                yield from check.generator(step_events)
            
              File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_step.py", line 468, in core_dagster_event_sequence_for_step
                for event_or_input_value in step_input.source.load_input_object(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            
              File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 364, in load_input_object
                yield from _load_input_with_input_manager(input_manager, load_input_context)
            
              File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 612, in _load_input_with_input_manager
                with op_execution_error_boundary(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            
              File "/usr/local/lib/python3.12/contextlib.py", line 158, in __exit__
                self.gen.throw(value)
            
              File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 75, in op_execution_error_boundary
                raise RetryRequestedFromPolicy(
  
          ''',
        }),
        'eventType': 'STEP_FAILURE',
        'level': 'ERROR',
        'message': 'Execution of step "enriched_data.process_chunk[11]" failed.',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.process_chunk[11]',
        'timestamp': '1758808877726',
      }),
      dict({
        'error': None,
        'eventType': None,
        'level': 'ERROR',
        'message': "Dependencies for step enriched_data.concat_chunk_list failed: ['enriched_data.process_chunk[11]']. Not executing.",
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.concat_chunk_list',
        'timestamp': '1758808877786',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'DEBUG',
        'message': 'Multiprocess executor: parent process exiting after 6.79s (pid: 1)',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808878387',
      }),
      dict({
        'error': None,
        'eventType': 'RUN_FAILURE',
        'level': 'ERROR',
        'message': 'Execution of run for "run_etl_pipeline" failed. Steps failed: [\'enriched_data.process_chunk[11]\'].',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808878519',
      }),
      dict({
        'error': None,
        'eventType': 'ENGINE_EVENT',
        'level': 'INFO',
        'message': 'Process for run exited (pid: 1).',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': None,
        'timestamp': '1758808878602',
      }),
      dict({
        'error': None,
        'eventType': 'ASSET_FAILED_TO_MATERIALIZE',
        'level': 'INFO',
        'message': 'Asset ["enriched_data"] failed to materialize',
        'runId': '85156191-170d-4229-8eba-14450b6ca9e3',
        'stepKey': 'enriched_data.concat_chunk_list',
        'timestamp': '1758808880071',
      }),
    ]),
    'run_id': '85156191-170d-4229-8eba-14450b6ca9e3',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[log_success_logs_with_errors_text_text]
  '''
  Logs for run 85156191-170d-4229-8eba-14450b6ca9e3:
  
  TIMESTAMP            LEVEL    STEP_KEY                  MESSAGE
  --------------------------------------------------------------------------------
  2025-09-25 14:01:05  DEBUG    enriched_data.concat_chu  run_etl_pipeline intends to materialize asset ["enriched_data"]
  2025-09-25 14:01:05  INFO                               Launched as an automatic retry
  2025-09-25 14:01:05  INFO                               
  2025-09-25 14:01:07  INFO                               
  2025-09-25 14:01:07  INFO                               Sending a request to the agent to execute steps in the user cloud
  2025-09-25 14:01:07  INFO                               [DagsterCloudAgent] Agent 3a659214 is launching run 85156191-170d-4229-8eba-14450b6ca9e3
  2025-09-25 14:01:07  INFO                               [CloudK8sRunLauncher] Creating Kubernetes run worker job
  2025-09-25 14:01:07  INFO                               [CloudK8sRunLauncher] Kubernetes run worker job created
  2025-09-25 14:01:10  INFO                               Starting run metrics thread with container_metrics_enabled=True and python_metrics_enabled=False
  2025-09-25 14:01:10  INFO                               Started process for run (pid: 1).
  2025-09-25 14:01:11  DEBUG                              Started execution of run for "run_etl_pipeline".
  2025-09-25 14:01:11  DEBUG                              Executing steps using multiprocess executor: parent process (pid: 1)
  2025-09-25 14:01:11  DEBUG    enriched_data.process_ch  Launching subprocess for "enriched_data.process_chunk[11]".
  2025-09-25 14:01:12  DEBUG    enriched_data.process_ch  Executing step "enriched_data.process_chunk[11]" in subprocess.
  2025-09-25 14:01:13  DEBUG    enriched_data.process_ch  Starting initialization of resources [api, io_manager].
  2025-09-25 14:01:13  DEBUG    enriched_data.process_ch  Finished initialization of resources [api, io_manager].
  2025-09-25 14:01:13  DEBUG                              Started capturing logs in process (pid: 16).
  2025-09-25 14:01:13  DEBUG    enriched_data.process_ch  Started execution of step "enriched_data.process_chunk[11]".
  2025-09-25 14:01:13  DEBUG    enriched_data.process_ch  Loading file from: /opt/dagster/dagster_home/storage/385defa2-7ac6-4d18-8a88-585a42393d9c/enriched_data.split_rows/result/11 using PickledObjectFilesystemIOManager...
  2025-09-25 14:01:13  DEBUG    enriched_data.process_ch  Execution of step "enriched_data.process_chunk[11]" failed and has requested a retry.
  2025-09-25 14:01:13  DEBUG    enriched_data.process_ch  Launching subprocess for "enriched_data.process_chunk[11]".
  2025-09-25 14:01:14  DEBUG    enriched_data.process_ch  Executing step "enriched_data.process_chunk[11]" in subprocess.
  2025-09-25 14:01:15  DEBUG    enriched_data.process_ch  Starting initialization of resources [api, io_manager].
  2025-09-25 14:01:15  DEBUG    enriched_data.process_ch  Finished initialization of resources [api, io_manager].
  2025-09-25 14:01:15  DEBUG                              Started capturing logs in process (pid: 26).
  2025-09-25 14:01:15  DEBUG    enriched_data.process_ch  Started re-execution (attempt # 2) of step "enriched_data.process_chunk[11]".
  2025-09-25 14:01:15  DEBUG    enriched_data.process_ch  Loading file from: /opt/dagster/dagster_home/storage/385defa2-7ac6-4d18-8a88-585a42393d9c/enriched_data.split_rows/result/11 using PickledObjectFilesystemIOManager...
  2025-09-25 14:01:15  DEBUG    enriched_data.process_ch  Execution of step "enriched_data.process_chunk[11]" failed and has requested a retry.
  2025-09-25 14:01:15  DEBUG    enriched_data.process_ch  Launching subprocess for "enriched_data.process_chunk[11]".
  2025-09-25 14:01:16  DEBUG    enriched_data.process_ch  Executing step "enriched_data.process_chunk[11]" in subprocess.
  2025-09-25 14:01:17  DEBUG    enriched_data.process_ch  Starting initialization of resources [api, io_manager].
  2025-09-25 14:01:17  DEBUG    enriched_data.process_ch  Finished initialization of resources [api, io_manager].
  2025-09-25 14:01:17  DEBUG                              Started capturing logs in process (pid: 36).
  2025-09-25 14:01:17  DEBUG    enriched_data.process_ch  Started re-execution (attempt # 3) of step "enriched_data.process_chunk[11]".
  2025-09-25 14:01:17  DEBUG    enriched_data.process_ch  Loading file from: /opt/dagster/dagster_home/storage/385defa2-7ac6-4d18-8a88-585a42393d9c/enriched_data.split_rows/result/11 using PickledObjectFilesystemIOManager...
  2025-09-25 14:01:17  ERROR    enriched_data.process_ch  Execution of step "enriched_data.process_chunk[11]" failed.
  
  Stack Trace:
      File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_plan.py", line 246, in dagster_event_sequence_for_step
        yield from check.generator(step_events)
      File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_step.py", line 468, in core_dagster_event_sequence_for_step
        for event_or_input_value in step_input.source.load_input_object(
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 364, in load_input_object
        yield from _load_input_with_input_manager(input_manager, load_input_context)
      File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/inputs.py", line 612, in _load_input_with_input_manager
        with op_execution_error_boundary(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File "/usr/local/lib/python3.12/contextlib.py", line 158, in __exit__
        self.gen.throw(value)
      File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 75, in op_execution_error_boundary
        raise RetryRequestedFromPolicy(
  
  2025-09-25 14:01:17  ERROR    enriched_data.concat_chu  Dependencies for step enriched_data.concat_chunk_list failed: ['enriched_data.process_chunk[11]']. Not executing.
  2025-09-25 14:01:18  DEBUG                              Multiprocess executor: parent process exiting after 6.79s (pid: 1)
  2025-09-25 14:01:18  ERROR                              Execution of run for "run_etl_pipeline" failed. Steps failed: ['enriched_data.process_chunk[11]'].
  2025-09-25 14:01:18  INFO                               Process for run exited (pid: 1).
  2025-09-25 14:01:20  INFO     enriched_data.concat_chu  Asset ["enriched_data"] failed to materialize
  
  Total log entries: 41
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[run_error_invalid_run_id_json]
  dict({
    'error': "Run not found: ''",
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[run_error_run_not_found_text]
  '''
  Error querying Dagster Plus API: Run not found: nonexistent-run-id
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[run_success_canceled_run_json]
  dict({
    'created_at': 1751036896.306532,
    'ended_at': 1751036909.142719,
    'id': 'e0248005-fc38-4e55-a9fb-472c8694303b',
    'job_name': 'run_etl_pipeline',
    'started_at': 1751036903.35325,
    'status': 'CANCELED',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[run_success_failed_run_json]
  dict({
    'created_at': 1757703542.251137,
    'ended_at': 1757703554.673739,
    'id': '4db16a22-4124-4d43-bd4c-ea0aeaa78172',
    'job_name': 'snowflake_insights_import',
    'started_at': 1757703550.780887,
    'status': 'FAILURE',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[run_success_single_run_json]
  dict({
    'created_at': 1757703683.741368,
    'ended_at': 1757703732.670455,
    'id': '2e562bd3-7e72-4448-9f05-32bad2ea8046',
    'job_name': '__ASSET_JOB',
    'started_at': 1757703690.474944,
    'status': 'SUCCESS',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[run_success_single_run_text_text]
  '''
  Run ID: 2e562bd3-7e72-4448-9f05-32bad2ea8046
  Status: DgApiRunStatus.SUCCESS
  Created: 1757703683.741368
  Started: 1757703690.474944
  Ended: 1757703732.670455
  Pipeline: __ASSET_JOB
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[secret_success_multiple_secrets_json]
  dict({
    'items': list([
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '9138919ca1b44065b1911ef4c4e92cfa',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'SNOWFLAKE_USER',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2023-05-04T19:14:15.542825Z',
        'updated_by': dict({
          'email': 'lopp@elementl.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '87198b0f905d4a90809595b310388e2d',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'SNOWFLAKE_ROLE',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2023-11-29T21:58:48.844959Z',
        'updated_by': dict({
          'email': 'izzy@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '6d627d934f3445a59cc80a0700af6d65',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'SNOWFLAKE_USERNAME',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2023-02-28T21:57:07.192470Z',
        'updated_by': dict({
          'email': 'lopp@elementl.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '4fdd87f4356d44dbbda1ee2f79936a59',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'SNOWFLAKE_ACCOUNT',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2023-05-04T19:12:08.067031Z',
        'updated_by': dict({
          'email': 'lopp@elementl.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'd09927cee20d4e599e766eb765c09519',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'AWS_REGION',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2023-11-30T15:18:08.570713Z',
        'updated_by': dict({
          'email': 'izzy@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'ef00b8a20b484620a261a50519afd644',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'SNOWFLAKE_HOST',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2023-12-11T23:27:02.879755Z',
        'updated_by': dict({
          'email': 'izzy@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': False,
        'id': 'c607dcb8d19c4f80a2caf0bc1409fdd3',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'DAGSTER_DBT_PARSE_PROJECT_ON_LOAD',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2024-04-05T17:52:55.019563Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '0db2f8eec4e1434982b435227f050783',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'AWS_S3_BUCKET',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2024-04-09T20:03:38.240532Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'b1467177bc8e4235b655edcfba6ca340',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'AZURE_POWERBI_CLIENT_SECRET_ID',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2024-10-09T13:43:43.483920Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'e7b8bc919e4c491e985d6f34cd155604',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'AZURE_POWERBI_CLIENT_ID',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2024-10-09T01:13:45.360461Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '7981b0db240a4c02b7ff4663a696efcc',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'AZURE_POWERBI_CLIENT_SECRET',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2024-10-09T01:13:56.007341Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '48b8c1ad099545cdbbf44a8b0c520922',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'AZURE_POWERBI_TENANT_ID',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2024-10-09T01:14:04.180889Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '58fe4b5791b74556b394167a504876cc',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'AZURE_POWERBI_WORKSPACE_ID',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2024-10-09T01:14:12.436403Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '0eb6b13ae2fd4ac2b3d2e6f44688401c',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'SNOWFLAKE_SCHEMA',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-06-27T19:20:59.521047Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'a6c8104f3ede4c41935bdd9895acd805',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'EXAMPLE_ENVIRONMENT_VARIABLE',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-09-22T20:18:39.564529Z',
        'updated_by': dict({
          'email': 'colton@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'c192d89000034a259062630a7fa58aad',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'MWAA_AWS_ACCESS_KEY_ID',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-03-08T03:26:30.092809Z',
        'updated_by': dict({
          'email': 'colton@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'bb813ff1bba04e179540839173faf9ed',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'MWAA_AWS_SECRET_ACCESS_KEY',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-03-08T03:26:41.762188Z',
        'updated_by': dict({
          'email': 'colton@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': False,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '05ed2d9c9ac246adac68389d48ab448a',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'DATABRICKS_TOKEN',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-07-26T00:32:00.876120Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': False,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '18d411d2f8e143159fc348cfe2b9f578',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'DATABRICKS_HOST',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-07-26T00:32:11.161514Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': False,
        'id': '5e55512ef0164d6e92b050e54b0a2082',
        'local_deployment_scope': False,
        'location_names': list([
        ]),
        'name': 'DATABRICKS_HOST',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-07-26T00:32:44.377634Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': False,
        'id': '65645109569c4acfa4b9f74de40329ce',
        'local_deployment_scope': False,
        'location_names': list([
        ]),
        'name': 'DATABRICKS_TOKEN',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-07-26T00:33:33.657806Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': '2d34f85706f44d77a33620ae5c3ef96b',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'GITHUB_TOKEN',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-08-11T19:39:12.247125Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
      dict({
        'all_branch_deployments_scope': True,
        'can_edit_secret': True,
        'can_view_secret_value': True,
        'full_deployment_scope': True,
        'id': 'f1a0dee193ac4f3d9a5c88e7f5169a26',
        'local_deployment_scope': True,
        'location_names': list([
        ]),
        'name': 'SNOWFLAKE_KEY',
        'specific_branch_deployment_scope': None,
        'update_timestamp': '2025-09-10T17:02:38.934973Z',
        'updated_by': dict({
          'email': 'christian@dagsterlabs.com',
        }),
        'value': None,
      }),
    ]),
    'total': 23,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[secret_success_multiple_secrets_text_text]
  '''
  Name: SNOWFLAKE_USER
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: lopp@elementl.com
  Updated: 2023-05-04 19:14:15
  
  Name: SNOWFLAKE_ROLE
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: izzy@dagsterlabs.com
  Updated: 2023-11-29 21:58:48
  
  Name: SNOWFLAKE_USERNAME
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: lopp@elementl.com
  Updated: 2023-02-28 21:57:07
  
  Name: SNOWFLAKE_ACCOUNT
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: lopp@elementl.com
  Updated: 2023-05-04 19:12:08
  
  Name: AWS_REGION
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: izzy@dagsterlabs.com
  Updated: 2023-11-30 15:18:08
  
  Name: SNOWFLAKE_HOST
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: izzy@dagsterlabs.com
  Updated: 2023-12-11 23:27:02
  
  Name: DAGSTER_DBT_PARSE_PROJECT_ON_LOAD
  Locations: All code locations
  Scopes: All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2024-04-05 17:52:55
  
  Name: AWS_S3_BUCKET
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2024-04-09 20:03:38
  
  Name: AZURE_POWERBI_CLIENT_SECRET_ID
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2024-10-09 13:43:43
  
  Name: AZURE_POWERBI_CLIENT_ID
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2024-10-09 01:13:45
  
  Name: AZURE_POWERBI_CLIENT_SECRET
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2024-10-09 01:13:56
  
  Name: AZURE_POWERBI_TENANT_ID
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2024-10-09 01:14:04
  
  Name: AZURE_POWERBI_WORKSPACE_ID
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2024-10-09 01:14:12
  
  Name: SNOWFLAKE_SCHEMA
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2025-06-27 19:20:59
  
  Name: EXAMPLE_ENVIRONMENT_VARIABLE
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: colton@dagsterlabs.com
  Updated: 2025-09-22 20:18:39
  
  Name: MWAA_AWS_ACCESS_KEY_ID
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: colton@dagsterlabs.com
  Updated: 2025-03-08 03:26:30
  
  Name: MWAA_AWS_SECRET_ACCESS_KEY
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: colton@dagsterlabs.com
  Updated: 2025-03-08 03:26:41
  
  Name: DATABRICKS_TOKEN
  Locations: All code locations
  Scopes: Full Deployment, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2025-07-26 00:32:00
  
  Name: DATABRICKS_HOST
  Locations: All code locations
  Scopes: Full Deployment, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2025-07-26 00:32:11
  
  Name: DATABRICKS_HOST
  Locations: All code locations
  Scopes: All Branch Deployments
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2025-07-26 00:32:44
  
  Name: DATABRICKS_TOKEN
  Locations: All code locations
  Scopes: All Branch Deployments
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2025-07-26 00:33:33
  
  Name: GITHUB_TOKEN
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2025-08-11 19:39:12
  
  Name: SNOWFLAKE_KEY
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Can Edit: Yes
  Can View Value: Yes
  Updated By: christian@dagsterlabs.com
  Updated: 2025-09-10 17:02:38
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[secret_success_single_secret_json]
  dict({
    'all_branch_deployments_scope': True,
    'can_edit_secret': True,
    'can_view_secret_value': True,
    'full_deployment_scope': True,
    'id': 'a6c8104f3ede4c41935bdd9895acd805',
    'local_deployment_scope': True,
    'location_names': list([
    ]),
    'name': 'EXAMPLE_ENVIRONMENT_VARIABLE',
    'specific_branch_deployment_scope': None,
    'update_timestamp': '2025-09-22T20:18:39.564529Z',
    'updated_by': dict({
      'email': 'colton@dagsterlabs.com',
    }),
    'value': None,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[secret_success_single_secret_text_text]
  '''
  Name: EXAMPLE_ENVIRONMENT_VARIABLE
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Permissions:
    Can Edit: Yes
    Can View Value: Yes
  
  Value: <hidden - use --show-value to display>
  
  Updated By: colton@dagsterlabs.com
  Updated: 2025-09-22 20:18:39
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[secret_success_single_secret_with_value_json]
  dict({
    'all_branch_deployments_scope': True,
    'can_edit_secret': True,
    'can_view_secret_value': True,
    'full_deployment_scope': True,
    'id': 'a6c8104f3ede4c41935bdd9895acd805',
    'local_deployment_scope': True,
    'location_names': list([
    ]),
    'name': 'EXAMPLE_ENVIRONMENT_VARIABLE',
    'specific_branch_deployment_scope': None,
    'update_timestamp': '2025-09-22T20:18:39.564529Z',
    'updated_by': dict({
      'email': 'colton@dagsterlabs.com',
    }),
    'value': 'Hello, World!',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[secret_success_single_secret_with_value_text_text]
  '''
  Name: EXAMPLE_ENVIRONMENT_VARIABLE
  Locations: All code locations
  Scopes: Full Deployment, All Branch Deployments, Local Deployment
  Permissions:
    Can Edit: Yes
    Can View Value: Yes
  
  Value:
    Hello, World!
  
  Updated By: colton@dagsterlabs.com
  Updated: 2025-09-22 20:18:39
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_empty_filtered_sensors_json]
  dict({
    'items': list([
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'orders_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'ASSET',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'watch_s3_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': '''
          
              This sensor launches execution of freshness checks for the provided assets. The sensor will
              only launch a new execution of a freshness check if the check previously passed, but enough
              time has passed that the check could be overdue again. Once a check has failed, the sensor
              will not launch a new execution until the asset has been updated (which should automatically
              execute the check).
              
        ''',
        'name': 'weekly_freshness_check_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'mwaa_hooli_airflow_01__airflow_dag_status_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
    ]),
    'total': 6,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_empty_sensors_json]
  dict({
    'items': list([
      dict({
        'description': None,
        'name': 'dbt_code_version_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'STOPPED',
      }),
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'orders_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'ASSET',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'watch_s3_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': '''
          
              This sensor launches execution of freshness checks for the provided assets. The sensor will
              only launch a new execution of a freshness check if the check previously passed, but enough
              time has passed that the check could be overdue again. Once a check has failed, the sensor
              will not launch a new execution until the asset has been updated (which should automatically
              execute the check).
              
        ''',
        'name': 'weekly_freshness_check_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'mwaa_hooli_airflow_01__airflow_dag_status_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
    ]),
    'total': 7,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_empty_sensors_text_text]
  '''
  Name: dbt_code_version_sensor
  Status: STOPPED
  Type: STANDARD
  Description: None
  
  Name: default_automation_condition_sensor
  Status: RUNNING
  Type: AUTO_MATERIALIZE
  Description: None
  
  Name: orders_sensor
  Status: RUNNING
  Type: ASSET
  Description: None
  
  Name: watch_s3_sensor
  Status: RUNNING
  Type: STANDARD
  Description: None
  
  Name: weekly_freshness_check_sensor
  Status: RUNNING
  Type: STANDARD
  Description: 
      This sensor launches execution of freshness checks for the provided assets. The sensor will
      only launch a new execution of a freshness check if the check previously passed, but enough
      time has passed that the check could be overdue again. Once a check has failed, the sensor
      will not launch a new execution until the asset has been updated (which should automatically
      execute the check).
      
  
  Name: default_automation_condition_sensor
  Status: RUNNING
  Type: AUTO_MATERIALIZE
  Description: None
  
  Name: mwaa_hooli_airflow_01__airflow_dag_status_sensor
  Status: RUNNING
  Type: STANDARD
  Description: None
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_error_empty_sensor_name_json]
  dict({
    'error': 'Exhausted 0 responses',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_error_invalid_status_filter_json]
  '''
  Usage: dg api sensor list [OPTIONS]
  Try 'dg api sensor list -h' for help.
  
  Error: Invalid value for '--status': 'INVALID_STATUS' is not one of 'RUNNING', 'STOPPED', 'PAUSED'.
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_error_multiple_sensors_same_name_json]
  dict({
    'error': 'Exhausted 0 responses',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_error_sensor_not_found_json]
  dict({
    'error': 'Exhausted 0 responses',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_error_sensor_not_found_text_text]
  '''
  Error: Failed to get sensor: Exhausted 0 responses
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_filtered_sensors_paused_json]
  dict({
    'items': list([
    ]),
    'total': 0,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_filtered_sensors_paused_text_text]
  '''
  
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_filtered_sensors_running_json]
  dict({
    'items': list([
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'orders_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'ASSET',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'watch_s3_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': '''
          
              This sensor launches execution of freshness checks for the provided assets. The sensor will
              only launch a new execution of a freshness check if the check previously passed, but enough
              time has passed that the check could be overdue again. Once a check has failed, the sensor
              will not launch a new execution until the asset has been updated (which should automatically
              execute the check).
              
        ''',
        'name': 'weekly_freshness_check_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'mwaa_hooli_airflow_01__airflow_dag_status_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
    ]),
    'total': 6,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_filtered_sensors_running_text_text]
  '''
  Name: default_automation_condition_sensor
  Status: RUNNING
  Type: AUTO_MATERIALIZE
  Description: None
  
  Name: orders_sensor
  Status: RUNNING
  Type: ASSET
  Description: None
  
  Name: watch_s3_sensor
  Status: RUNNING
  Type: STANDARD
  Description: None
  
  Name: weekly_freshness_check_sensor
  Status: RUNNING
  Type: STANDARD
  Description: 
      This sensor launches execution of freshness checks for the provided assets. The sensor will
      only launch a new execution of a freshness check if the check previously passed, but enough
      time has passed that the check could be overdue again. Once a check has failed, the sensor
      will not launch a new execution until the asset has been updated (which should automatically
      execute the check).
      
  
  Name: default_automation_condition_sensor
  Status: RUNNING
  Type: AUTO_MATERIALIZE
  Description: None
  
  Name: mwaa_hooli_airflow_01__airflow_dag_status_sensor
  Status: RUNNING
  Type: STANDARD
  Description: None
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_filtered_sensors_stopped_json]
  dict({
    'items': list([
      dict({
        'description': None,
        'name': 'dbt_code_version_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'STOPPED',
      }),
    ]),
    'total': 1,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_filtered_sensors_stopped_text_text]
  '''
  Name: dbt_code_version_sensor
  Status: STOPPED
  Type: STANDARD
  Description: None
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_multiple_sensors_json]
  dict({
    'items': list([
      dict({
        'description': None,
        'name': 'dbt_code_version_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'STOPPED',
      }),
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'orders_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'ASSET',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'watch_s3_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': '''
          
              This sensor launches execution of freshness checks for the provided assets. The sensor will
              only launch a new execution of a freshness check if the check previously passed, but enough
              time has passed that the check could be overdue again. Once a check has failed, the sensor
              will not launch a new execution until the asset has been updated (which should automatically
              execute the check).
              
        ''',
        'name': 'weekly_freshness_check_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'default_automation_condition_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'AUTO_MATERIALIZE',
        'status': 'RUNNING',
      }),
      dict({
        'description': None,
        'name': 'mwaa_hooli_airflow_01__airflow_dag_status_sensor',
        'next_tick_timestamp': None,
        'sensor_type': 'STANDARD',
        'status': 'RUNNING',
      }),
    ]),
    'total': 7,
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_multiple_sensors_text_text]
  '''
  Name: dbt_code_version_sensor
  Status: STOPPED
  Type: STANDARD
  Description: None
  
  Name: default_automation_condition_sensor
  Status: RUNNING
  Type: AUTO_MATERIALIZE
  Description: None
  
  Name: orders_sensor
  Status: RUNNING
  Type: ASSET
  Description: None
  
  Name: watch_s3_sensor
  Status: RUNNING
  Type: STANDARD
  Description: None
  
  Name: weekly_freshness_check_sensor
  Status: RUNNING
  Type: STANDARD
  Description: 
      This sensor launches execution of freshness checks for the provided assets. The sensor will
      only launch a new execution of a freshness check if the check previously passed, but enough
      time has passed that the check could be overdue again. Once a check has failed, the sensor
      will not launch a new execution until the asset has been updated (which should automatically
      execute the check).
      
  
  Name: default_automation_condition_sensor
  Status: RUNNING
  Type: AUTO_MATERIALIZE
  Description: None
  
  Name: mwaa_hooli_airflow_01__airflow_dag_status_sensor
  Status: RUNNING
  Type: STANDARD
  Description: None
  
  '''
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_single_sensor_running_json]
  dict({
    'description': None,
    'name': 'orders_sensor',
    'next_tick_timestamp': None,
    'sensor_type': 'ASSET',
    'status': 'RUNNING',
  })
# ---
# name: TestDynamicCommandExecution.test_command_execution[sensor_success_single_sensor_running_text_text]
  '''
  Name: orders_sensor
  Status: RUNNING
  Type: ASSET
  Description: None
  
  '''
# ---
